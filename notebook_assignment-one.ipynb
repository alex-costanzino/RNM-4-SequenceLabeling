{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"CRWCzaDnyW1G"},"outputs":[],"source":["'''\n","MSc students in Artificial Intelligence\n","@ Alma Mater Studiorum, University of Bologna\n","December, 2021\n","'''"]},{"cell_type":"markdown","source":["# Assignment No. 1: recurrent neural models for sequence labeling\n","Part-of-speech tagging (POS) is one of the most important classification task in natural language processing. \n","\n","In this assignment we experimented a bidirectional model, along three variations, implemented with Tensorflow API, based on Keras backend, and tested the performances with different input data strategies and hyperparameters."],"metadata":{"id":"GwNdYioddHa_"}},{"cell_type":"markdown","metadata":{"id":"riKbt7YN0X1p"},"source":["## Components\n","A.y. 2021/2022\n","\n","|  Surname | Name   | Matricola   | Accademic e-mail   |  \n","|---|---|---|---|  \n","|Costanzino          | Alex   | 984919   | alex.costanzino@studio.unibo.it  |\n","|Costante          |  Marco  | 973866  | marco.costante@studio.unibo.it  |\n","|Stramiglio          | Alessandra   | 973983  | alessandr.stramiglio@studio.unibo.it  |\n","|Wen          | Xiaowei   | 982501  | xiaowei.wen@studio.unibo.it  |"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3LI0kyin0mYr"},"outputs":[],"source":["import os, shutil\n","import urllib.request\n","\n","from zipfile import ZipFile\n","from natsort import natsorted\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","\n","from typing import List, Dict, OrderedDict, Tuple\n","\n","from tqdm import tqdm\n","import gensim\n","import gensim.downloader as gloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6mnTYsW70iE"},"outputs":[],"source":["!pip install git+https://github.com/artemmavrin/focal-loss.git\n","import focal_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2Ru1sGu25fK"},"outputs":[],"source":["# Random seed to repeat experiments.\n","np.random.seed(115)\n","tf.random.set_seed(115)"]},{"cell_type":"markdown","metadata":{"id":"H9_bQJF50CWp"},"source":["## Dataset extraction\n","We decided to feed the neural networks with sentences, instead of the entire documents, since the lengths of the documents have too variability with respect to the lengths of the sentences. In this way we have a better trade-off in the padding and truncation process. \n","\n","In this section we will download the dataset from an url, split the documents according to the task and load them as dataframes.\n","Each step will create separate structures in order to ensure the independency of training, validation and test set.\n","\n","The following routine is a simple cleaner of Colab's workspace:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uiEh1Zoz_36o"},"outputs":[],"source":["# Delete everything from the workspace.\n","def clean_workspace(f):\n","  if os.path.isfile(f):\n","    os.remove(f)\n","  elif os.path.isdir(f):\n","    list_file = os.listdir(f)\n","    for x in list_file:\n","      clean_workspace(os.path.join(os.getcwd(), f, x))\n","    os.rmdir(f)"]},{"cell_type":"markdown","metadata":{"id":"ZJSrIOysxpKU"},"source":["Dataset downloading and extraction:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":535,"status":"ok","timestamp":1639818049440,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"},"user_tz":-60},"id":"Lkp3vYRk0BSk","outputId":"664d5163-d182-42d8-957d-a638e9afd556"},"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully downloaded.\n","Successfully extracted.\n"]}],"source":["dataset_url = 'https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip'\n","dataset_folder = os.path.join(os.getcwd(), 'dataset')\n","\n","if not os.path.exists(dataset_folder):\n","    os.makedirs(dataset_folder)\n","\n","dataset_path = os.path.join(dataset_folder, 'dependency_treebank.zip')\n","\n","if not os.path.exists(dataset_path):\n","    urllib.request.urlretrieve(dataset_url, dataset_path)\n","    print('Successfully downloaded.')\n","\n","unzipped_dataset_path = os.path.join(os.getcwd(), \"dependency_treebank\")\n","\n","if os.path.exists(unzipped_dataset_path):\n","  clean_workspace(unzipped_dataset_path)\n","\n","with ZipFile(dataset_path, 'r') as dataset:\n","  dataset.extractall()\n","  print('Successfully extracted.')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z21CtmUP-xI4"},"outputs":[],"source":["# We prefer to keep our files sorted accordingly to incrasing number. \n","files = os.listdir(os.path.join(\"dependency_treebank\"))\n","files = natsorted(files)"]},{"cell_type":"markdown","metadata":{"id":"CZ_U54hvySAV"},"source":["Dataset splitting:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XaUd51pO75Zc"},"outputs":[],"source":["# Splitting the dataset into different folders.\n","train_folder =  os.path.join(\"/content\", \"dependency_treebank\", \"train\")\n","test_folder =  os.path.join(\"/content\", \"dependency_treebank\", \"test\")\n","val_folder = os.path.join(\"/content\", \"dependency_treebank\", \"val\")\n","\n","folders = [train_folder, test_folder, val_folder]\n","\n","for f in folders:\n","  if not os.path.exists(f):\n","      os.makedirs(f)\n","\n","for i in range (1, len(files) + 1):\n","  new_dest = ''\n","  \n","  if i <= 100:\n","    new_dest = os.path.join(train_folder, files[i-1])\n","  elif 100 < i <= 150:\n","    new_dest = os.path.join(test_folder, files[i-1])\n","  else:\n","    new_dest = os.path.join(val_folder, files[i-1])\n","\n","  shutil.move(os.path.join('dependency_treebank', files[i-1]), new_dest)"]},{"cell_type":"markdown","metadata":{"id":"qdxuk0KQEowH"},"source":["## Data loading\n","Now we will take each sentences in the documents, with the associated tag, putting them in a new entry of the corresponding dataframe.\n","\n","We will load the splits into separate dataframes, composed by three columns: `file_name`, `words`, `tags`.\n","\n","They will be stored as lists so we must be careful of eventual side effects while tackling the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tp-h41eVEoTy"},"outputs":[],"source":["def get_dict(file_name:str, word_list: list, tag_list: list) -> dict:\n","  return {\"file_name\": file_name, \"words\" : list(word_list), \"tags\" : list(tag_list)}\n","\n","def load_file(file_name: str, file_path: str) -> list:\n","    with open(file_path, \"r\") as file_ds:\n","        sentence_list = []\n","        word_list = []\n","        tag_list = []\n","\n","        dataframe_rows = {}\n","        \n","        for line in file_ds:\n","            splitted_row = line.split(\"\t\")\n","\n","            if len(splitted_row) == 3:\n","                word_list.append(splitted_row[0].lower())\n","                tag_list.append(splitted_row[1])\n","              \n","            else:\n","                if len(word_list) != len(tag_list):\n","                  raise ValueError(\"Male, numero dei tag diverso da quello dei word\")\n","                sentence_list.append(get_dict(file_name, word_list,tag_list))\n","                word_list = []\n","                tag_list = []\n","                dataframe_rows = {}\n","\n","    if len(word_list) != 0:\n","      sentence_list.append(get_dict(file_name, word_list, tag_list))\n","\n","    return sentence_list\n","\n","def load_dataframes():\n","    cwd = os.getcwd()\n","    datasets = []\n","\n","    for folder in [\"train\", \"test\", \"val\"]:\n","        data_frame = []\n","        current_path = os.path.join(cwd, \"dependency_treebank\", folder)\n","        ds_files = natsorted(os.listdir(current_path))\n","        sentences_list = []\n","\n","        for ds_file in ds_files:\n","            sentences_list += load_file(ds_file, os.path.join(current_path, ds_file))\n","          \n","        frame = pd.DataFrame.from_dict(sentences_list)\n","        datasets.append(frame)\n","\n","    return datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2mM0JxIQEyPz"},"outputs":[],"source":["df_train, df_val, df_test = load_dataframes()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1639818049871,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"},"user_tz":-60},"id":"7rUykKojiOy4","outputId":"5a5c6f84-35fb-4c87-b6b4-2e57fc5314e7"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-76631194-5be8-46cd-b8a0-f6082c5d8aa9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_name</th>\n","      <th>words</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>wsj_0151.dp</td>\n","      <td>[intelogic, trace, inc., ,, san, antonio, ,, t...</td>\n","      <td>[NNP, NNP, NNP, ,, NNP, NNP, ,, NNP, ,, VBD, P...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>wsj_0151.dp</td>\n","      <td>[the, move, boosts, intelogic, chairman, asher...</td>\n","      <td>[DT, NN, VBZ, NNP, NNP, NNP, NNP, POS, NN, TO,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>wsj_0151.dp</td>\n","      <td>[mr., ackerman, already, is, seeking, to, oust...</td>\n","      <td>[NNP, NNP, RB, VBZ, VBG, TO, VB, NNP, NNP, IN,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>wsj_0151.dp</td>\n","      <td>[the, action, followed, by, one, day, an, inte...</td>\n","      <td>[DT, NN, VBN, IN, CD, NN, DT, NNP, NN, IN, PRP...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>wsj_0151.dp</td>\n","      <td>[in, new, york, stock, exchange, composite, tr...</td>\n","      <td>[IN, NNP, NNP, NNP, NNP, JJ, NN, NN, ,, NNP, N...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76631194-5be8-46cd-b8a0-f6082c5d8aa9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-76631194-5be8-46cd-b8a0-f6082c5d8aa9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-76631194-5be8-46cd-b8a0-f6082c5d8aa9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     file_name  ...                                               tags\n","0  wsj_0151.dp  ...  [NNP, NNP, NNP, ,, NNP, NNP, ,, NNP, ,, VBD, P...\n","1  wsj_0151.dp  ...  [DT, NN, VBZ, NNP, NNP, NNP, NNP, POS, NN, TO,...\n","2  wsj_0151.dp  ...  [NNP, NNP, RB, VBZ, VBG, TO, VB, NNP, NNP, IN,...\n","3  wsj_0151.dp  ...  [DT, NN, VBN, IN, CD, NN, DT, NNP, NN, IN, PRP...\n","4  wsj_0151.dp  ...  [IN, NNP, NNP, NNP, NNP, JJ, NN, NN, ,, NNP, N...\n","\n","[5 rows x 3 columns]"]},"metadata":{},"execution_count":11}],"source":["# Sanity checks.\n","df_train.head()\n","df_val.head()\n","df_test.head()"]},{"cell_type":"markdown","metadata":{"id":"hDq-FSe56s9Z"},"source":["## Data Inspection\n","Now we will define a function that extract some infos about the dataset which can be useful while we are modelling our nets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xYaQS4Oi6yEC"},"outputs":[],"source":["def get_info(dataset: pd.DataFrame) -> tuple:\n","  number_of_sentences = len(dataset)\n","  max_sequence_length = max([len(sentence) for sentence in dataset['words']])\n","  number_of_tags = len(set(dataset['tags'].sum()))\n","  min_sequence_length = min([len(sentence) for sentence in dataset['words']])\n","  distribution_of_lengths = [len(sentence) for sentence in dataset['words']]\n","\n","  return number_of_sentences, max_sequence_length, number_of_tags, min_sequence_length, distribution_of_lengths"]},{"cell_type":"markdown","source":["We will now check the distrubition of the lenghts in the training and validation set to seek a good sequence lenght for the LSTMs."],"metadata":{"id":"Fas3YgvBWrX8"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"elapsed":1717,"status":"ok","timestamp":1639818051582,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"},"user_tz":-60},"id":"NyTwt2Gg6wF0","outputId":"d02b9dc1-3bae-420f-d5fb-de064f8adac9"},"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbMElEQVR4nO3de7ycVX3v8c/XhGtAQsI2BALsKAhGK5fuw6V4TikX5VbDeZVyoBwabWxKX+VUWywGbRXUajhHRXzVqimIATkQRJAcoApGLi/PaSM73CFQAgaSkMsGiSB4IfA7f6y1ZZg9s2f23jN7ZiXf9+s1rz3P/feseZ7fXrPW8zyjiMDMzMrzpk4HYGZmo+MEbmZWKCdwM7NCOYGbmRXKCdzMrFBO4GZmhXICr0HSKknHtnB9H5D044rhX0h6a4vW/XFJl+b3vZJC0sQWrXvvHOuEVqxvBNudJukuSS9K+uJ4brsUks6UdGsL13eHpA+1an1jJenrkv6h1fNuabo+gbc6mY6VpKMkrRnLOiJip4h4shXbiYjPRURLTrzqso6Ip3Osr7Zi/SMwD3gWeHNEnDseG2zF5zqeIuKqiHjvaJaVdIGkb7c6por1j/mcjYizI+IzrZ53PFRX2Nqp6xO41deqmnYX2gd4JHyX2RZpCz5ux19EdPULWAUcW2P8m4D5wBPAc8C1wJQ8rRcIYA7wNKk294mKZXcAFgHPAyuA84A1Vdv8KPAA8HNgMbA9MAn4JfAa8Iv82qNGbFOBJcALwE+AzwA/rpgewL75/YnAI8CLwNq83ZrbAS4ArgO+ndf9oTzu21X7PQ94BlgHfLRiu98CPlsxfNTgfgNX5u39Mm/vvIr1Tczz7JH362fASuDPK9Z1Qf4Mrsj78jDQN8zn+nvA3bl87wZ+ryLGV4Df5DhqffZDyqxi2snAfcAm4P8B7x7t58rYjrEJwMfzsi8Cy4G98rQDgNtyOT4GnNbMvlWVwQcYekydDTye9/2rgGosd3wu21fyft6fx99BOk7/b972rcBuFcsdnstzE3A/cFSduIY7jubmsrorz/sdYH3+LO4C3lnrWCUfp8C5wEbScf3BUc47Ffg/pPPnbuCzleVYtS/bk8615/J+3w1My9N2AS7L61+b1zMBeAfwK+DVvP+b2pofxyMJjynA+gn8w8C/AzOA7YBvAFdXnVz/QkrWBwK/Bt6Rpy8A7gR2zcs/wNAE/hPSSTyFlOTPrjxAGsR8DelknwS8K3/A9RL4OuA/5/e7AofU2w4pSb4CnEJKLjtQO4Ffnbf9O8DAYPkxTAKvVdYMTeB3Af+cD+yD8rqProjtV6QENAH4PPDvdcpnCumf51nAROCMPDy1Vpw1lq9XZgeTTtrDcgxz8j5tN5rPlbEdY38HPAjsDyhPn5o/l9XAB/O+H0xK/rOG27caZfABhh5TNwGTgb3zZ3N8nWUvIB8zFePuIP2zeXvenzuABXnanqQkdiLpuDsuD/c0c85WlNUVef93yOP/DNg5l+2XgfsqlvntMZA/m83Ap4FtchwvA7uOYt5r8mtHYFb+LOol8L8gJfsdScfT75Ka9QBuyMfDJOAtpOPqL2p9Nu18ldyEcjapxrMmIn5NOihPrfp6dmFE/DIi7ifVGg7M408DPhcRz0fEGuArNdb/lYh4JiJ+RvoQD2omqNzh90fAJyPipYh4iFTbr+cVYJakN+d47mmwiX+LiO9FxGsR8cs681yYt/0gcDkpQY6JpL2AI4GPRcSvIuI+4FLgTytm+3FE3BKpzfxKXi/vaicBj0fElRGxOSKuBh4F/rDJcOqV2TzgGxGxLCJejYhFpKR6eMWyI/lcx3KMfQj4+4h4LJL7I+I50jeEVRFxed73e4HvAn/cYN+asSAiNkXE08DtDfatlssj4j/ycXVtxfL/Hbglf7avRcRtQD8pOY7EBfm4/CVARHwzIl6sKNsDJe1SZ9lXgE9HxCsRcQupdrv/SOatODc/FREvR8QjND43p5IqW69GxPKIeEHSNNK+fyTvz0bgYuD0EZRFS5ScwPcBbpC0SdImUm3qVWBaxTzrK96/DOyU3+9B+s87qPJ9o2Ub6SHVrCrX+dQw8/8R6WB4StKdko5osP5asQ43z1Ok/R2rPYCfRcSLVeves2K4usy2r9PeuQdDy6R6XcOpV2b7AOcOHhP5uNiLN+7/SD7XsRxje5FqtLXWeVhVjGcCuzfYt2aM9phttPw+wB9XxfweYPoI1//b41LSBEkLJD0h6QVSrR1gtzrLPhcRm+vE1+y8tc7N4c6nK4EfANdIekbS/5S0Dak8tgHWVZTHN0g18XFVcgJfDZwQEZMrXttHxNomll1H+lo8aK8RbLdRx9oA6Stc5Tr3rruyiLsjYjbpw/8eqeYz3Haa6dir3vYz+f1LpK+Dg3bnjYZb9zPAFEk7V627mfKuta59qsY1va5hymw18I9Vx8SOuYbfcLU1xo3lGFsNvK3O+Dur1rlTRPxlg31rpZF2Dq8GrqyKeVJELBjh+ivH/wkwGziW1J7cm8drhLGNxOC52dS5n2vwF0bELFKfzcmkb5yrSd/sdqsojzdHxDsHF21P+EOVksC3kbR9xWsi8HXgHyXtAyCpR9LsJtd3LXC+pF0l7QmcM4JYNgBT633Vy80H1wMXSNpR0ixSW+wQkrbN1/PuEhGvkDpWXmtmOw38Q972O0ltrYvz+PuAEyVNkbQ78JEa+1bz+vSIWE3qxPp8/gzeTeqUGs3laLcAb5f0J5ImSvpvpPbImxot2KDM/gU4W9JhSiZJOqnqn049tcp7LMfYpcBnJO2XY3m3pKl5H98u6SxJ2+TXf5L0jgb71kobgF5JzZ7/3wb+UNL7cs15+3zZ5Yw689c9jirsTEqCz5EqFZ9rMpZRq3FuHsAbmwDfQNIfSPqd3PTyAqlJ5bWIWEfq5P2ipDdLepOkt0n6/bzoBmCGpG3bu0flJPBbSL3ag68LgEtIV0TcKulFUmfTYU2u79OknuqfAj8kXdnx62YWjIhHSZ2ET+avT7WaJ84hfWVbT+pguXyYVZ4FrMpfI88mfZ1udjv13Em6SmQp8IWIGLzh40pSO+0q0gG4uGq5zwN/n7f30RrrPYNUU3qG1InzqYj44QjiAqCiLfhc0gl8HnByRDzb5CrqlVk/8OfAP5E6RVeSOpSaialWeY/lGPsSqaJwK+nkv4zUefci8F5Se+kzpGPkIlJHXt19a7Hv5L/PSWrYxp7/ec8mXVUzQKqB/h3180ej4whSh+ZTpG9dj5DKdjycQ6rxryedD1dT/9zfnZQbXiA1n92Zl4GU+Lclxf58nm+wSelHpKuw1kt6Fn57w92/tnpnFOFLbSX9JXB6RPx+w5nNbIsh6SJg94io+S2525VSA28pSdMlHZm/+uxPqgne0Om4zKy9JB2Qm7Mk6VBSM2Cx5/7WekfUtqRe45mkC/SvIV3fbGZbtp1JzSZ7kNqqvwjc2NGIxsBNKGZmhdoqm1DMzLYE49qEsttuu0Vvb+94btLMrHjLly9/NiJ6qsePawLv7e2lv79/PDdpZlY8STXv5m6qCUXS30h6WNJDkq7OF/LPlLRM0kpJi8fjonUzM3tdwwSe71T8a9KjQd9FeirX6aSbDy6OiH1JF7LPbWegZmb2Rs12Yk4Edsi3sO9IepbI0aS7jyA90euU1odnZmb1NEzg+cE9XyA9iH0d6eHry0kPKh984tca6jxJTtI8Sf2S+gcGBloTtZmZNdWEsivpOQgzSRe/TyL9qkdTImJhRPRFRF9Pz5BOVDMzG6VmmlCOBX4aEQP5CWnXkx7sP1mvP+t5BqN7rKiZmY1SMwn8aeDw/PhFAceQnsB1O3BqnmcOBd+OamZWombawJeROivvIf3G35uAhcDHgL+VtJL0s0OXtTFOMzOr0tSNPBHxKeBTVaOfBA5teURmZtYUPwulBXrn30zv/Js7HYaZbWWcwM3MCuUE3gaukZvZeHACNzMrlBO4mVmhnMDNzArlBG5mVigncDOzQm2tv0rfFr7yxMzGk2vgZmaFcgI3MyuUE7iZWaGcwM3MCuUEPgq+Vd7MuoETuJlZoZzAzcwK5QRuZlYoJ3Azs0I1vBNT0v7A4opRbwU+CVyRx/cCq4DTIuL51ofYvdyRaWad1MyPGj8WEQdFxEHA7wIvAzcA84GlEbEfsDQPm5nZOBlpE8oxwBMR8RQwG1iUxy8CTmllYGZmNryRJvDTgavz+2kRsS6/Xw9Mq7WApHmS+iX1DwwMjDJMMzOr1nQCl7Qt8H7gO9XTIiKAqLVcRCyMiL6I6Ovp6Rl1oGZm9kYjqYGfANwTERvy8AZJ0wHy342tDs7MzOobSQI/g9ebTwCWAHPy+znAja0KakvjW+/NrB2aSuCSJgHHAddXjF4AHCfpceDYPGxmZuOkqV/kiYiXgKlV454jXZViZmYd4DsxzcwK5QRuZlYoJ3Azs0I5gZuZFcoJ3MysUE1dhbK1Gbxme9WCk9q6/nZuw8y2fK6Bm5kVyjXwEfDdlGbWTVwDNzMrlBO4mVmhnMDNzArlBG5mVigncDOzQvkqlGGM9aoTX7ViZu3kGriZWaGcwDvMv9ZjZqPlBG5mVqhmf1JtsqTrJD0qaYWkIyRNkXSbpMfz313bHayZmb2u2Rr4JcD3I+IA4EBgBTAfWBoR+wFL87CZmY2Thglc0i7AfwEuA4iI30TEJmA2sCjPtgg4pV1BmpnZUM3UwGcCA8Dlku6VdGn+lfppEbEuz7MemNauIM3MbKhmEvhE4BDgaxFxMPASVc0lERFA1FpY0jxJ/ZL6BwYGxhqvmZllzSTwNcCaiFiWh68jJfQNkqYD5L8bay0cEQsjoi8i+np6eloRs5mZ0UQCj4j1wGpJ++dRxwCPAEuAOXncHODGtkRoZmY1NXsr/f8ArpK0LfAk8EFS8r9W0lzgKeC09oRoZma1NJXAI+I+oK/GpGNaG46ZmTXLD7Oq4FvazawkvpXezKxQroGPI9fwzayVXAM3MyuUE7iZWaGcwM3MCuUEbmZWKCdwM7NCOYF3Gf/Empk1ywnczKxQTuBdqrom7pq5mVVzAjczK5QTuJlZoZzAzcwK5QRuZlYoJ3Azs0L5aYT4KYFmVibXwM3MCtVUDVzSKuBF4FVgc0T0SZoCLAZ6gVXAaRHxfHvC3PL5W4CZjdRIauB/EBEHRcTgb2POB5ZGxH7A0jxsZmbjZCxNKLOBRfn9IuCUsYdjZmbNajaBB3CrpOWS5uVx0yJiXX6/HphWa0FJ8yT1S+ofGBgYY7hmZjao2atQ3hMRayW9BbhN0qOVEyMiJEWtBSNiIbAQoK+vr+Y8ZmY2ck3VwCNibf67EbgBOBTYIGk6QP67sV1BmpnZUA0TuKRJknYefA+8F3gIWALMybPNAW5sV5BmZjZUM00o04AbJA3O/78j4vuS7gaulTQXeAo4rX1hmplZtYYJPCKeBA6sMf454Jh2BGVmZo35Tkwzs0I5gZuZFcoJ3MysUE7gZmaFcgI3MyuUnwfe5fyUQjOrxzVwM7NCOYEXqnf+za6dm23lnMDNzArlBG5mVqituhPTTRBmVjLXwM3MCuUEbmZWKCfwwvlqFLOtlxO4mVmhnMDNzArlBG5mVqimE7ikCZLulXRTHp4paZmklZIWS9q2fWGamVm1kdTAPwysqBi+CLg4IvYFngfmtjIwq82dlmY2qKkELmkGcBJwaR4WcDRwXZ5lEXBKOwI0M7Pamq2Bfxk4D3gtD08FNkXE5jy8BtizxbGZmdkwGt5KL+lkYGNELJd01Eg3IGkeMA9g7733HnGArVLZ7LBqwUkdi8PMrFWaqYEfCbxf0irgGlLTySXAZEmD/wBmAGtrLRwRCyOiLyL6enp6WhCymZlBEwk8Is6PiBkR0QucDvwoIs4EbgdOzbPNAW5sW5RmZjbEWK4D/xjwt5JWktrEL2tNSGZm1owRPU42Iu4A7sjvnwQObX1IZmbWjK3yeeC+jtrMtgS+ld7MrFBO4GZmhXICNzMrlBO4mVmhnMDNzArlBG5mVigncDOzQjmBb2H8vHCzrYcTuJlZoZzAzcwK5QS+hXJTitmWzwnczKxQTuBmZoVyAjczK5QTuJlZoZzAzcwK5QRuZlaohglc0vaSfiLpfkkPS7owj58paZmklZIWS9q2/eHaSPlyQrMtVzM18F8DR0fEgcBBwPGSDgcuAi6OiH2B54G57QvTzMyqNUzgkfwiD26TXwEcDVyXxy8CTmlLhGZmVlNTbeCSJki6D9gI3AY8AWyKiM15ljXAnnWWnSepX1L/wMBAK2I2MzOaTOAR8WpEHATMAA4FDmh2AxGxMCL6IqKvp6dnlGGamVm1EV2FEhGbgNuBI4DJkibmSTOAtS2OzczMhtHMVSg9kibn9zsAxwErSIn81DzbHODGdgVpZmZDTWw8C9OBRZImkBL+tRFxk6RHgGskfRa4F7isjXGamVmVhgk8Ih4ADq4x/klSe7iZmXWA78Q0MyuUE7iZWaGcwM3MCuUEbmZWKCdwM7NCNXMZYZEGn8C3asFJHY5kfPiJg2ZbH9fAzcwK5QRuZlYoJ3Azs0I5gZuZFcoJ3MysUE7gZmaFcgI3MyuUE7iZWaGcwM3MCuUEbmZWKCdwM7NCOYGbmRWq4cOsJO0FXAFMAwJYGBGXSJoCLAZ6gVXAaRHxfPtCHR0/5MnMtlTN1MA3A+dGxCzgcOCvJM0C5gNLI2I/YGkeNjOzcdIwgUfEuoi4J79/EVgB7AnMBhbl2RYBp7QrSDMzG2pEbeCSekm/UL8MmBYR6/Kk9aQmllrLzJPUL6l/YGBgDKEOr3f+zW4uMbOtStMJXNJOwHeBj0TEC5XTIiJI7eNDRMTCiOiLiL6enp4xBWtmZq9rKoFL2oaUvK+KiOvz6A2Spufp04GN7QnRzMxqaZjAJQm4DFgREV+qmLQEmJPfzwFubH14ZmZWTzO/iXkkcBbwoKT78riPAwuAayXNBZ4CTmtPiGZmVkvDBB4RPwZUZ/IxrQ1n7NyROTqV5ba1/BC0Wel8J6aZWaGcwM3MCuUEvpXydfNm5XMCNzMrlBO4mVmhnMDNzArlBG5mVigncDOzQjmBm5kVygnczKxQTuBbCV/3bbblcQI3MyuUE7gN4dq6WRmcwM3MCuUEbmZWKCdwM7NCOYGbmRWqmd/E/KakjZIeqhg3RdJtkh7Pf3dtb5hmZlatmd/E/BbwT8AVFePmA0sjYoGk+Xn4Y60PrzFfLTEyIymvwXmrf2Kt3ngzG18Na+ARcRfws6rRs4FF+f0i4JQWx2VmZg2Mtg18WkSsy+/XA9PqzShpnqR+Sf0DAwOj3JyZmVUbcydmRAQQw0xfGBF9EdHX09Mz1s2ZmVk22gS+QdJ0gPx3Y+tCMjOzZjTTiVnLEmAOsCD/vbFlEVnXcoexWXdp5jLCq4F/A/aXtEbSXFLiPk7S48CxedjMzMZRwxp4RJxRZ9IxLY7FzMxGYLRNKLaFcLOIWbl8K72ZWaGKq4G7xmhmlrgGbmZWKCdwM7NCFdeEYuPPzVZm3ck1cDOzQjmBm5kVygnczKxQTuBmZoVyArcx651/86g6Oke7nJklTuBmZoVyAjczK5SvA7dRq27+qNccMvjjx/4xZLPWcg3czKxQTuDWNYbr1HSHp9lQTuBmZoVyAjczK9SYOjElHQ9cAkwALo2Itv02pr8+l6vZzs7RrLO6g3RQqzpO29nxWuK6663XHdSdMeoauKQJwFeBE4BZwBmSZrUqMDMzG95YmlAOBVZGxJMR8RvgGmB2a8IyM7NGFBGjW1A6FTg+Ij6Uh88CDouIc6rmmwfMy4P7A4+NcFO7Ac+OKsjx4xhbo4QYoYw4HWNrdEuM+0RET/XItt/IExELgYWjXV5Sf0T0tTCklnOMrVFCjFBGnI6xNbo9xrE0oawF9qoYnpHHmZnZOBhLAr8b2E/STEnbAqcDS1oTlpmZNTLqJpSI2CzpHOAHpMsIvxkRD7cssteNuvllHDnG1ighRigjTsfYGl0d46g7Mc3MrLN8J6aZWaGcwM3MCtW1CVzS8ZIek7RS0vxOxzNI0l6Sbpf0iKSHJX04j58i6TZJj+e/u3Y4zgmS7pV0Ux6eKWlZLs/FueO5oyRNlnSdpEclrZB0RBeW49/kz/khSVdL2r7TZSnpm5I2SnqoYlzNclPylRzrA5IO6WCM/yt/1g9IukHS5Ipp5+cYH5P0vvGIsV6cFdPOlRSSdsvDHSnL4XRlAu/y2/Q3A+dGxCzgcOCvcmzzgaURsR+wNA930oeBFRXDFwEXR8S+wPPA3I5E9UaXAN+PiAOAA0nxdk05StoT+GugLyLeReqsP53Ol+W3gOOrxtUrtxOA/fJrHvC1DsZ4G/CuiHg38B/A+QD5/DkdeGde5p9zDuhUnEjaC3gv8HTF6E6VZX0R0XUv4AjgBxXD5wPndzquOrHeCBxHusN0eh43HXisgzHNIJ3ERwM3ASLdTTaxVvl2KMZdgJ+SO9IrxndTOe4JrAamkK7Yugl4XzeUJdALPNSo3IBvAGfUmm+8Y6ya9l+Bq/L7N5zfpCvbjuhUWeZx15EqFauA3TpdlvVeXVkD5/UTZ9CaPK6rSOoFDgaWAdMiYl2etB6Y1qGwAL4MnAe8loenApsiYnMe7obynAkMAJfnpp5LJU2ii8oxItYCXyDVwtYBPweW031lCfXLrVvPpT8D/jW/76oYJc0G1kbE/VWTuipO6NImlBJI2gn4LvCRiHihclqkf88duT5T0snAxohY3ontj8BE4BDgaxFxMPASVc0lnSxHgNyOPJv0z2YPYBI1vm53m06XWyOSPkFqiryq07FUk7Qj8HHgk52OpRndmsC7+jZ9SduQkvdVEXF9Hr1B0vQ8fTqwsUPhHQm8X9Iq0hMijya1NU+WNHjjVjeU5xpgTUQsy8PXkRJ6t5QjwLHATyNiICJeAa4nlW+3lSXUL7euOpckfQA4GTgz/6OB7orxbaR/2Pfnc2gGcI+k3emuOIHuTeBde5u+JAGXASsi4ksVk5YAc/L7OaS28XEXEedHxIyI6CWV248i4kzgduDUTsc3KCLWA6sl7Z9HHQM8QpeUY/Y0cLikHfPnPhhjV5VlVq/clgB/mq+gOBz4eUVTy7hS+gGY84D3R8TLFZOWAKdL2k7STFIn4U86EWNEPBgRb4mI3nwOrQEOycdr15Tlb3WyAb5Bx8KJpJ7qJ4BPdDqeirjeQ/p6+gBwX36dSGpnXgo8DvwQmNIFsR4F3JTfv5V0UqwEvgNs1wXxHQT057L8HrBrt5UjcCHwKPAQcCWwXafLEria1Cb/CinBzK1XbqQO7K/m8+hB0hU1nYpxJakNefC8+XrF/J/IMT4GnNDJsqyavorXOzE7UpbDvXwrvZlZobq1CcXMzBpwAjczK5QTuJlZoZzAzcwK5QRuZlYoJ3Azs0I5gZuZFer/AxxNrkezNepcAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAY7ElEQVR4nO3deZRcZZ3G8e9jwiJBDSFtDGRpFEQjI8vJsIgeGdwCQYNHRBAxOmAGj4w4B8XgCuMWzrjBuCKIERECKJIBRsHIMm5Iwg4B2RqSkA1INLgggd/88b5NKpWqruru6q56k+dzTp/Uvbfq3l+9996n3n7vrY4iAjMzK8/z2l2AmZkNjAPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQW3SAS+qR9MYWru99kn5dMf2kpJe2aN2fkHROftwtKSSNbNG6J+VaR7Riff3Y7jhJN0haJ+krw7ntUkg6RtLVLVzfdZKOb9X6BljDQZKWVkzfJemgZp47gG19R9KnB/r6TtcxAd7qMB2swR44ABGxfUQ82IrtRMQXI6IlJ151W0fEI7nWZ1qx/n6YBTwGvDAiTh6ODbZivw6niLggIt48kNdKOk3Sj1pdU6tFxKsi4rrBrqe6A5XXfUJEfG6w626VVn+AdkyAW32t6ml3oMnA3eFvk5kNTER0xA/QA7yxxvznAbOBB4DHgYuBMXlZNxDATOARUm/ukxWvfT4wF1gDLAZOAZZWbfOjwO3An4B5wLbAKOBvwLPAk/lnpxq17QjMB/4M/AH4HPDriuUB7JofHwrcDawDluXt1twOcBpwKfCjvO7j87wfVb3vWcCjwHLgoxXb/QHw+Yrpg3rfN3B+3t7f8vZOqVjfyPycnfL7egK4H/hAxbpOy/vgh/m93AVM7WO/vga4KbfvTcBrKmp8GvhHrqPWvt+kzSqWHQbcCqwFfgu8eqD7lcEdYyOAT+TXrgMWARPzslcA1+R2vBc4spn3VtUG72PTY+oE4L783r8JqMbrpuW2fTq/z9vy/OtIx+lv8ravBsZWvG7/3J5rgduAg+rU9XHg0qp5ZwJn5cfvJ51z64AHgX+rdTxWn/ukc/YHpHP2buBjVc/t3U/r8vK35/mvBP4OPJPf79o658IHSMf0E6RjfKf+tm1+7r7AQtL5uRL4aqM2BL6Q6/t7rvEbg87NoQrkfhdSP8BPAn4PTAC2Ab4LXFh1cn0v7/g9gaeAV+blc4DrgR3y62+vceD8gXQSj8kH3Am1DrI6NV9EOtlHAXuQTsR6Ab4ceF1+vAOwT73tkELyaeBwUrg8n9oBfmHe9j8Bq9lwElQftBtto7qt2TTAbwC+RQq9vfK6D66o7e+kABoBfAn4fZ32GUM6EY8FRgJH5+kda9VZ4/X12mxvYBWwX65hZn5P2wxkvzK4Y+xjwB3A7oDy8h3zfllCCrKRuebHgCl9vbcabfA+Nj2mrgBGA5PyvplW57WnkY+ZinnXkQLw5fn9XAfMyct2Jn2AHUo67t6Up7tqrHsy8FfgBXl6RH5P++fp6cDLcpu8Pj+35jHPxgE+B/i/vN8mAndWPfedbPjQfRfwF2B8rbaqPsaAg/M+2Cfv5/8Gbhhg2/4OODY/3r7ifffZhrm9j29VbpYwhHICqcezNCKeIh2UR1QNK5weEX+LiNtIn3h75vlHAl+MiDURsRQ4q8b6z4qIRyPiCeB/SIHVUL7g9w7gMxHxl4i4k9Tbr+dpYIqkF+Z6bm6wid9FxM8i4tmI+Fud55yet30HcB4pIAdF0kTgQODjEfH3iLgVOAd4b8XTfh0RV0UaMz+fDe1dbTpwX0ScHxHrI+JC4B7grU2WU6/NZgHfjYgbI+KZiJhLCtX9K17bn/06mGPseOBTEXFvJLdFxOOk3xB6IuK8/N5vAX5CCqC+3lsz5kTE2oh4BLi2wXur5byI+GM+ri6ueP17gKvyvn02Iq4h9TIPrV5BRDwM3Ay8Pc86GPhrRPw+L78yIh7IbXI9qaf/uiZqOxL4QkQ8ERFLqDpnI+KSvF+fjYh5pN7yvk2+72OA70fEzXk/nwocIKm74jnNtu3TwK6SxkbEk73vm360YSuUEOCTgcskrZW0ltSbegYYV/GcFRWP/0r6RIT0Sb2kYlnl40avbaSL1LOqXOfDfTz/HaSd+LCk6yUd0GD9tWrt6zkPk97vYO0EPBER66rWvXPFdHWbbVtnnH4nNm2T6nX1pV6bTQZO7j0m8nExkY3ff3/262COsYmkHm2tde5XVeMxwEsavLdmDPSYbfT6ycA7q2p+LTC+znp+zIZOw7vzNACSDpH0e0lP5PUcCoxtorbqc3aj40fSeyXdWlHfHk2ut3fdz60vIp4k9Y77Orbrte1xpN9i7pF0k6TD8vz+tuGglBDgS4BDImJ0xc+2EbGsidcuJ/1a3GtiP7bb6MLaamB91Ton1V1ZxE0RMQN4MfAzUs+nr+00c2GvetuP5sd/AbarWPYSNtbXuh8Fxkh6QdW6m2nvWuuaXDWv6XX10WZLSL20ymNiu9zDb7jaGvMGc4wtIQ0V1Jp/fdU6t4+IDzZ4b63UzDFUaQlwflXNoyJiTp3nXwIcJGkCqSf+YwBJ25B+2/gyMC4iRgNXkYZTGllOnXNK0mTSUNaJpGG40aQhlt71Nnq/Gx2PkkaRhrv6fWxHxH0RcTRp/50BXJrX16gN+7tP+tRpAb6VpG0rfkYC3wG+kHcekrokzWhyfRcDp0raQdLOpB3frJXAjpJeVGthHj74KXCapO0kTSGNxW5C0tb5ft4XRcTTpAsfzzaznQY+nbf9KtJY67w8/1bgUEljJL0E+EiN91bz/vT8a+tvgS/lffBqUm9jILejXQW8XNK7JY2U9C5gCmmcsU8N2ux7wAmS9lMyStL0qg+demq192COsXOAz0naLdfyakk75vf4cknHStoq//yzpFc2eG+ttBLoltTsef4j4K2S3iJpRN7/vQG9iYhYTRrTPQ94KCIW50Vbk8aYVwPrJR0CNHsrZOU5OwH494plo0gBuBpA0vtJPfBeK4EJkraus+4LgfdL2it/yHwRuDEiepqs7TmS3iOpKyKeJV2shLQPG7Vh3XNvIDotwK8i3SXQ+3Ma6cr2fOBqSetIF5v2a3J9/wksBR4Cfkm6s+OpZl4YEfeQdviD+VehWsMTJ5J+xVpBulhyXh+rPBbokfRn0pjrMf3YTj3Xk66oLwC+HBG9X/g4nzRO20Mae5xX9bovAZ/K2/tojfUeTbp49yhwGfDZiPhlP+oCoGIs+GTSr6qnAIdFxGNNrqJemy0k3U3wDdJF0ftJF7CaqalWew/mGPsqKXSuJgXxucDz8xDUm4GjSO24gtRT26av99Zil+R/H5fUcIw9f3jPIN1Vs5rUm/wYfefEj4E3UjF8kt/7h0ntsoY0vDK/yZpPJw1zPERq0/Mr1ns38BXSBcSVpIv3v6l47a9Id0WtkLTJMZaP4U+TfjtYTvrN6agm66o2DbhL0pOk4+eofI2kURueSbq+skbSWfDcF5kGtP8V0dIefUeT9EFSQ7++3bWYmQ1Wp/XAW0rSeEkHSnqepN1JPcHL2l2XmVkrbK7f8Ou1Neme3l1I41QXke5vNjMr3hY1hGJmtjnZrIdQzMw2Z8M6hDJ27Njo7u4ezk2amRVv0aJFj0VEV/X8YQ3w7u5uFi5cOJybNDMrnqSa3/L2EIqZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4EOge/aVdM++st1lmNlmzgFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4EPItxOa2VBygJuZFcoBbmZWKAe4mVmhHOAt0Gis22PhZjYUHOBmZoVygJuZFcoBbmZWqJHNPElSD7AOeAZYHxFTJY0B5gHdQA9wZESsGZoyzcysWn964P8SEXtFxNQ8PRtYEBG7AQvytJmZDZPBDKHMAObmx3OBwwdfjpmZNavZAA/gakmLJM3K88ZFxPL8eAUwruXVmZlZXU2NgQOvjYhlkl4MXCPpnsqFERGSotYLc+DPApg0adKgii1d773gPXOmt7kSM9scNNUDj4hl+d9VwGXAvsBKSeMB8r+r6rz27IiYGhFTu7q6WlO1mZk1DnBJoyS9oPcx8GbgTmA+MDM/bSZw+VAVaWZmm2pmCGUccJmk3uf/OCJ+Lukm4GJJxwEPA0cOXZlmZlatYYBHxIPAnjXmPw68YSiKMjOzxvxNTDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK1eyfk7UW6v2zsuA/LWtmA+ceuJlZoRzgZmaFcoA3oXv2lRsNe5iZdQIHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAV7Bf/PEzEriADczK5QD3MysUA7wAfBQi5l1gqYDXNIISbdIuiJP7yLpRkn3S5onaeuhK9PMzKr1pwd+ErC4YvoM4GsRsSuwBjiulYWZmVnfmgpwSROA6cA5eVrAwcCl+SlzgcOHokAzM6ut2R7414FTgGfz9I7A2ohYn6eXAjvXeqGkWZIWSlq4evXqQRVrZmYbNAxwSYcBqyJi0UA2EBFnR8TUiJja1dU1kFWYmVkNI5t4zoHA2yQdCmwLvBA4ExgtaWTuhU8Alg1dmWZmVq1hDzwiTo2ICRHRDRwF/CoijgGuBY7IT5sJXD5kVZqZ2Saa6YHX83HgIkmfB24Bzm1NSeXwveBm1k79CvCIuA64Lj9+ENi39SWZmVkz/E1MM7NCOcDNzAo1mDHwzV71GLfHvM2sk7gHbmZWKAe4mVmhPITSQgMZYul9Tc+c6TWnzczqcQ/czKxQDnAzs0I5wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuX7wDuEv6ZvZv3lHriZWaEc4GZmhXKAm5kVymPgNXg82sxK4B64mVmhHOBmZoVygJuZFcoBbmZWKAe4mVmhHOBmZoVygHeo7tlX+nZGM+uTA9zMrFAOcDOzQjnAzcwK5QA3MytUwwCXtK2kP0i6TdJdkk7P83eRdKOk+yXNk7T10JdrZma9mumBPwUcHBF7AnsB0yTtD5wBfC0idgXWAMcNXZlmZlatYYBH8mSe3Cr/BHAwcGmePxc4fEgqNDOzmpr6c7KSRgCLgF2BbwIPAGsjYn1+ylJg5zqvnQXMApg0adJg6x0SJd1v3Vtrz5zpba7EzNqtqYuYEfFMROwFTAD2BV7R7AYi4uyImBoRU7u6ugZYppmZVevXXSgRsRa4FjgAGC2ptwc/AVjW4trMzKwPzdyF0iVpdH78fOBNwGJSkB+RnzYTuHyoijQzs001MwY+Hpibx8GfB1wcEVdIuhu4SNLngVuAc4ewTjMzq9IwwCPidmDvGvMfJI2Hm5lZG/ibmGZmhfL/Sl+oerc++vZCsy2He+BmZoVygJuZFcoBbmZWqC1mDLxyzNjjxGa2OXAP3MysUA5wM7NCOcDNzAq12QZ49+wri/ozsfVsLu/DzFpvsw1wM7PNnQPczKxQDnAzs0I5wM3MCuUANzMrlAPczKxQW8xX6UvnWwnNrJp74GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlaoLfo+cN9bbWYlcw/czKxQDnAzs0I5wM3MCtVwDFzSROCHwDgggLMj4kxJY4B5QDfQAxwZEWuGrtSB2VLHuXvfd8+c6W2uxMyGSjM98PXAyRExBdgf+JCkKcBsYEFE7AYsyNNmZjZMGgZ4RCyPiJvz43XAYmBnYAYwNz9tLnD4UBVpZmab6tdthJK6gb2BG4FxEbE8L1pBGmKp9ZpZwCyASZMmDbTOltpSh1XMbPPS9EVMSdsDPwE+EhF/rlwWEUEaH99ERJwdEVMjYmpXV9egijUzsw2aCnBJW5HC+4KI+GmevVLS+Lx8PLBqaEo0M7NaGga4JAHnAosj4qsVi+YDM/PjmcDlrS/PzMzqaWYM/EDgWOAOSbfmeZ8A5gAXSzoOeBg4cmhKtP7w+L7ZlqNhgEfErwHVWfyG1pZjZmbN8jcxzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyvUZvdfqvk+aDPbUrgHbmZWKAe4mVmhHOBmZoVygG+humdf6esFZoVzgJuZFcoBbmZWKAe4mVmhHOBmZoVygJuZFcoBbmZWKAe4mVmhHOBmZoVygJuZFcoBbmZWqOL/nKy/Dj44ve3XM2d6mysxs/5yD9zMrFAOcDOzQjnAzcwKVfwYuPWt+hqBx7rNNh/ugZuZFcoBbmZWKAe4mVmhGga4pO9LWiXpzop5YyRdI+m+/O8OQ1ummZlVa6YH/gNgWtW82cCCiNgNWJCnzcxsGDUM8Ii4AXiiavYMYG5+PBc4vMV1mZlZAwMdAx8XEcvz4xXAuHpPlDRL0kJJC1evXj3AzVkn8v9sb9Zeg76IGREBRB/Lz46IqRExtaura7CbMzOzbKABvlLSeID876rWlWRmZs0YaIDPB2bmxzOBy1tTjpmZNavhV+klXQgcBIyVtBT4LDAHuFjSccDDwJFDWWQl//nTwfGYtdnmo2GAR8TRdRa9ocW1mJlZP/ibmGZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhfL/Sm+bqPc/2fvPGJh1FvfAzcwK5QA3MyuUA9zMrFAeAzegtX9m1mPlZsPDPXAzs0I5wM3MCuUANzMrlMfAraHq8fF60x7zNhte7oGbmRXKAW5mVigHuJlZoYodA2/lfctmZiVyD9zMrFAOcDOzQhU7hGKdp96wVr0/T9vKbbbjFkbfPmnt5h64mVmhHOBmZoVygJuZFcpj4Dbs6o2VV//XbX1p1bjzUI7Pmw21QfXAJU2TdK+k+yXNblVRZmbW2IADXNII4JvAIcAU4GhJU1pVmJmZ9W0wPfB9gfsj4sGI+AdwETCjNWWZmVkjioiBvVA6ApgWEcfn6WOB/SLixKrnzQJm5cndgXv7uamxwGMDKnL4uMbWKKFGKKNO19ganVLj5Ijoqp455BcxI+Js4OyBvl7SwoiY2sKSWs41tkYJNUIZdbrG1uj0GgczhLIMmFgxPSHPMzOzYTCYAL8J2E3SLpK2Bo4C5remLDMza2TAQygRsV7SicAvgBHA9yPirpZVtsGAh1+GkWtsjRJqhDLqdI2t0dE1DvgippmZtZe/Sm9mVigHuJlZoTo2wDv1a/qSJkq6VtLdku6SdFKeP0bSNZLuy//u0OY6R0i6RdIVeXoXSTfm9pyXLzy3laTRki6VdI+kxZIO6MB2/I+8n++UdKGkbdvdlpK+L2mVpDsr5tVsNyVn5Vpvl7RPG2v8r7yvb5d0maTRFctOzTXeK+ktw1FjvTorlp0sKSSNzdNtacu+dGSAd/jX9NcDJ0fEFGB/4EO5ttnAgojYDViQp9vpJGBxxfQZwNciYldgDXBcW6ra2JnAzyPiFcCepHo7ph0l7Qx8GJgaEXuQLtYfRfvb8gfAtKp59drtEGC3/DML+HYba7wG2CMiXg38ETgVIJ8/RwGvyq/5Vs6AdtWJpInAm4FHKma3qy3ri4iO+wEOAH5RMX0qcGq766pT6+XAm0jfMB2f540H7m1jTRNIJ/HBwBWASN8mG1mrfdtU44uAh8gX0ivmd1I77gwsAcaQ7ti6AnhLJ7Ql0A3c2ajdgO8CR9d63nDXWLXs7cAF+fFG5zfpzrYD2tWWed6lpE5FDzC23W1Z76cje+BsOHF6Lc3zOoqkbmBv4EZgXEQsz4tWAOPaVBbA14FTgGfz9I7A2ohYn6c7oT13AVYD5+WhnnMkjaKD2jEilgFfJvXClgN/AhbReW0J9dutU8+lfwX+Nz/uqBolzQCWRcRtVYs6qk7o0CGUEkjaHvgJ8JGI+HPlskgfz225P1PSYcCqiFjUju33w0hgH+DbEbE38Beqhkva2Y4AeRx5BunDZidgFDV+3e407W63RiR9kjQUeUG7a6kmaTvgE8Bn2l1LMzo1wDv6a/qStiKF9wUR8dM8e6Wk8Xn5eGBVm8o7EHibpB7SX4g8mDTWPFpS7xe3OqE9lwJLI+LGPH0pKdA7pR0B3gg8FBGrI+Jp4Kek9u20toT67dZR55Kk9wGHAcfkDxrorBpfRvrAvi2fQxOAmyW9hM6qE+jcAO/Yr+lLEnAusDgivlqxaD4wMz+eSRobH3YRcWpETIiIblK7/SoijgGuBY5od329ImIFsETS7nnWG4C76ZB2zB4B9pe0Xd7vvTV2VFtm9dptPvDefAfF/sCfKoZahpWkaaShvbdFxF8rFs0HjpK0jaRdSBcJ/9COGiPijoh4cUR053NoKbBPPl47pi2f084B+AYXFg4lXal+APhku+upqOu1pF9PbwduzT+HksaZFwD3Ab8ExnRArQcBV+THLyWdFPcDlwDbdEB9ewELc1v+DNih09oROB24B7gTOB/Ypt1tCVxIGpN/mhQwx9VrN9IF7G/m8+gO0h017arxftIYcu95852K538y13gvcEg727JqeQ8bLmK2pS37+vFX6c3MCtWpQyhmZtaAA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQv0/I33GstoR1P8AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure()\n","n_t, _, _ = plt.hist(get_info(df_train)[-1], bins = [i for i in range(1, 150)], cumulative = False)\n","plt.title('Length distribution of sentences in the training set.');\n","\n","plt.figure()\n","n_v, _, _ = plt.hist(get_info(df_val)[-1], bins = [i for i in range(1, 150)], cumulative = False)\n","plt.title('Length distribution of sentences in the validation set.');"]},{"cell_type":"markdown","source":["For training, as maximum sequence length we considered 95th percentile of the lengths of the sentences of the training set.\n","\n","In our case we know that such length can be used also for testing, since the maximum length of the sentences of the test set is way shorter. \n","In a real-case scenario, where the test set is unknown, we should be careful when managing the test set to make inference, since we cannot truncate its sentences, otherwise it would change it, altering the performances."],"metadata":{"id":"5fV4HOeuZFtN"}},{"cell_type":"code","source":["maximum_sequence_length = round(np.percentile(n_t, 95))\n","print(f'The 0.95 percentile of the sequences lengths in the training set is {maximum_sequence_length}.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"URRBb4VnZF3E","executionInfo":{"status":"ok","timestamp":1639818052094,"user_tz":-60,"elapsed":519,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"}},"outputId":"c9df2874-a49b-47ae-b99d-262cc5fe7911"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The 0.95 percentile of the sequences lengths in the training set is 66.\n"]}]},{"cell_type":"markdown","metadata":{"id":"yI8P-Z3H6np7"},"source":["## Data processing\n","Now we will create routine to handle the download of GloVe embedding, the creation of embedding matrix and the out-of-vocaboulary words."]},{"cell_type":"markdown","metadata":{"id":"Ez9RcDiQAUBj"},"source":["### Out-Of-Vocaboulary words\n","First we define a routine that extracts from each dataset the set of unique words to seek for OOVs."]},{"cell_type":"code","source":["def get_word_listing(dataframe: pd.DataFrame):\n","  return set(dataframe[\"words\"].sum())"],"metadata":{"id":"d6JbNCU3cS5s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then we define a function that checks the OOVs."],"metadata":{"id":"dlrbzFS1cknI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"X2BFOFNBEMuz"},"outputs":[],"source":["def check_OOV_terms(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n","                    word_listing: List[str]):\n","    '''\n","    Checks differences between pre-trained embedding model vocabulary\n","    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.\n","    '''\n","\n","    embedding_vocabulary = set(embedding_model.vocab.keys())\n","    oov = set(word_listing).difference(embedding_vocabulary)\n","    return list(oov)"]},{"cell_type":"markdown","source":["### Vocaboularies creation"],"metadata":{"id":"sKmKqI8cc7Gj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wc_cxvHegV-m"},"outputs":[],"source":["from collections import OrderedDict\n","from typing import OrderedDict\n","\n","def build_vocabulary(df: pd.DataFrame) -> (OrderedDict[int, str], OrderedDict[str, int], OrderedDict[int, str], OrderedDict[str, int]):\n","    '''\n","    Given a dataset, builds the corresponding word vocabulary.\n","    '''\n","\n","    idx2word = OrderedDict()\n","    word2idx = OrderedDict()\n","\n","    idx2tag = OrderedDict()\n","    tag2idx = OrderedDict()\n","    \n","    curr_idx = 1 # Start at 1 since 0 is reserved for padding.\n","    for token in tqdm(df['words'].sum()):\n","        if token not in word2idx:\n","            word2idx[token] = curr_idx\n","            idx2word[curr_idx] = token\n","            curr_idx += 1\n","\n","    curr_idx = 1 # Start at 1 since 0 is reserved for padding.\n","    for tag in tqdm(np.unique(df['tags'].sum())):\n","        if tag not in tag2idx:\n","            tag2idx[tag] = curr_idx\n","            idx2tag[curr_idx] = tag\n","            curr_idx += 1\n","\n","    return idx2word, word2idx, idx2tag, tag2idx"]},{"cell_type":"markdown","metadata":{"id":"7zjG6Y-zDqg0"},"source":["### Embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j3rseJGIDph3","executionInfo":{"status":"ok","timestamp":1639818372629,"user_tz":-60,"elapsed":320540,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4e8e73c0-806a-4833-b413-fd1f7d6b558b"},"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 376.1/376.1MB downloaded\n"]}],"source":["def load_glove_embedding(embedding_dimension: int) -> gensim.models.keyedvectors.KeyedVectors:\n","    download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n","\n","    # Sanity check.\n","    try:\n","        embedded_model = gloader.load(download_path)\n","    except ValueError as e:\n","        print(\"Invalid embedding dimension: choose between: 50, 100, 200, 300.\")\n","        raise e\n","\n","    return embedded_model\n","\n","embedding_dimension = 300\n","embedding_model = load_glove_embedding(embedding_dimension) # Load embedding model with the chosen dimensionality."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRLLy2R3fDkh"},"outputs":[],"source":["def build_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors, embedding_dimension: int,\n","                           word2idx: Dict[str, int], vocab_size: int, oov_terms: List[str]) -> np.ndarray:\n","    '''\n","    Builds the embedding matrix of a specific dataset given a pre-trained word embedding model.\n","    '''\n","\n","    # Note: we take (vocab_size) + 1 since we start counting by 1, having reserved 0 for the padding.\n","    embedding_matrix = np.zeros((vocab_size + 1, embedding_dimension), dtype = np.float32) \n","\n","    for word, idx in tqdm(word2idx.items()):\n","        try:\n","            embedding_vector = embedding_model[word]\n","        except (KeyError, TypeError):\n","            embedding_vector = np.random.uniform(low = -0.05, high = 0.05, size = embedding_dimension)\n","\n","        embedding_matrix[idx] = embedding_vector\n","\n","    return embedding_matrix"]},{"cell_type":"markdown","metadata":{"id":"QYFynqFPvjkD"},"source":["### Matrix dataset preparation\n","Now we will put our data in form of matrixes to feed the models."]},{"cell_type":"code","source":["# Step 1: creation of vocaboulary for the training set and extraction of his OOVs.\n","idx2word_train, word2idx_train, idx2tag_train, tag2idx_train = build_vocabulary(df_train)\n","\n","oov_terms_train = check_OOV_terms(embedding_model, get_word_listing(df_train))\n","print(f'There are {len(oov_terms_train)} OOVs in the training set.')\n","\n","embedding_matrix_train = build_embedding_matrix(embedding_model, embedding_dimension, word2idx_train, len(word2idx_train), oov_terms_train)\n","print(\"Embedding matrix shape: {}\".format(embedding_matrix_train.shape))\n","\n","print('\\n')\n","# Step 2: creation of vocaboulary for the validation set and extraction of his OOVs, taking into account the ones already from training set.\n","idx2word_val, word2idx_val, idx2tag_val, tag2idx_val = build_vocabulary(df_val)\n","\n","oov_terms_val = check_OOV_terms(embedding_model, get_word_listing(df_val))\n","oov_terms_val = list(set(oov_terms_val).difference(set(oov_terms_train)))\n","print(f'There are {len(oov_terms_val)} new OOVs in the validation set.')\n","\n","embedding_matrix_val = build_embedding_matrix(embedding_model, embedding_dimension, word2idx_val, len(word2idx_val), oov_terms_val)\n","print(\"Embedding matrix shape: {}.\".format(embedding_matrix_val.shape))\n","\n","print('\\n')\n","# Step 3: creation of vocaboulary for the test set and extraction of his OOVs.\n","idx2word_test, word2idx_test, idx2tag_test, tag2idx_test = build_vocabulary(df_test)\n","\n","oov_terms_test = check_OOV_terms(embedding_model, get_word_listing(df_test))\n","oov_terms_test = list(set(oov_terms_test).difference((set(oov_terms_train).union(set(oov_terms_val)))))\n","print(f'There are {len(oov_terms_test)} new OOVs in the test set.')\n","\n","embedding_matrix_test = build_embedding_matrix(embedding_model, embedding_dimension, word2idx_test, len(word2idx_test), oov_terms_test)\n","print(\"Embedding matrix shape: {}.\".format(embedding_matrix_test.shape))\n","\n","print('\\n')\n","\n","# Whole embedding matrix.\n","embedding_matrix = np.concatenate((embedding_matrix_train, embedding_matrix_val, embedding_matrix_test))\n","print(\"Embedding matrix shape: {}.\".format(embedding_matrix.shape))\n","\n","#idx2word, word2idx, idx2tag, tag2idx = build_vocabulary(pd.concat([df_train, df_val, df_test]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PEwGJgYlfje1","executionInfo":{"status":"ok","timestamp":1639818374364,"user_tz":-60,"elapsed":1742,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"}},"outputId":"cf8b4118-8a5d-4eb4-8805-efe1b799fc62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 47356/47356 [00:00<00:00, 1669766.97it/s]\n","100%|██████████| 45/45 [00:00<00:00, 56816.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["There are 359 OOVs in the training set.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 7404/7404 [00:00<00:00, 181660.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Embedding matrix shape: (7405, 300)\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 31183/31183 [00:00<00:00, 1509573.78it/s]\n","100%|██████████| 44/44 [00:00<00:00, 184919.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["There are 189 new OOVs in the validation set.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5420/5420 [00:00<00:00, 166954.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Embedding matrix shape: (5421, 300).\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 15545/15545 [00:00<00:00, 1287325.38it/s]\n","100%|██████████| 40/40 [00:00<00:00, 103627.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["There are 128 new OOVs in the test set.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3407/3407 [00:00<00:00, 165508.38it/s]"]},{"output_type":"stream","name":"stdout","text":["Embedding matrix shape: (3408, 300).\n","\n","\n","Embedding matrix shape: (16234, 300).\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["At first we created the vocabularies of words and tags for the training set, we extracted the out-of-vocabularies (OOV) words for it and then its embedding matrix.\n","We assigned random vectors for the OOV words.\n","We repeated the same process for the validation set, taking into account the fact that the OOV words already considered for the training set, are not OOV words for the validation set. The same was done for the test set.\n","\n","Then, we concatenated all embedding matrixes into a single one, and merged the various vocabularies into a single one."],"metadata":{"id":"jmfI9rM38FvT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9fFFE_moJhWK"},"outputs":[],"source":["from keras.preprocessing.sequence import pad_sequences\n","from typing import OrderedDict\n","\n","def get_matrixes(dataframe: pd.DataFrame, max_sequence_length: int, word2idx: OrderedDict[str, int], tag2idx: OrderedDict[str, int]) -> (np.ndarray, np.ndarray):\n","  # Transform all words in the dataframe into their corresponding index.\n","  word_matrix = [[word2idx[dataframe['words'][j][i]] # j selects the row, i selects the word.\n","                for i in range(len(dataframe['words'][j]))] \n","                for j in range(len(dataframe))] \n","\n","  tag_matrix = [[tag2idx[dataframe['tags'][j][i]] # j selects the row, i selects the word.\n","               for i in range(len(dataframe['tags'][j]))] \n","               for j in range(len(dataframe))] \n","\n","  # Turn the list of lists into a matrix.\n","  for i in range(len(word_matrix)):\n","    word_matrix[i] = np.asarray(word_matrix[i])\n","      \n","  word_matrix = np.asarray(word_matrix);\n","\n","  for i in range(len(tag_matrix)):\n","    tag_matrix[i] = np.asarray(tag_matrix[i])\n","  \n","  tag_matrix = np.asarray(tag_matrix);\n","\n","  # Pad the sequences into the same length. Note that we need to pad to right since it's needed for Keras masking system.\n","  word_matrix = pad_sequences(word_matrix, maxlen = max_sequence_length, padding = 'post', truncating = 'post')\n","  tag_matrix = pad_sequences(tag_matrix, maxlen = max_sequence_length, padding = 'post', truncating = 'post')\n","\n","  # Add dimension to tag matrix to conform it to the net.\n","  tag_matrix = np.expand_dims(tag_matrix, axis = 2)\n","\n","  return word_matrix, tag_matrix"]},{"cell_type":"code","source":["word2idx = OrderedDict()\n","\n","word2idx.update(word2idx_train)\n","word2idx.update(word2idx_test)\n","word2idx.update(word2idx_val)\n","\n","tag2idx = OrderedDict()\n","\n","tag2idx.update(tag2idx_train)\n","tag2idx.update(tag2idx_test)\n","tag2idx.update(tag2idx_val)"],"metadata":{"id":"GunWjxDU2qWu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally, we put our dataframes into matrixes, padding and truncating the sentences, using the aforementioned vocabulary to encode the words into integers."],"metadata":{"id":"Rr_6ZtJa3Muk"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2252,"status":"ok","timestamp":1639819736183,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"},"user_tz":-60},"id":"d2imgWAtmA-k","outputId":"65d7aac7-18b9-4951-bf40-183e48847c92"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n"]},{"output_type":"stream","name":"stdout","text":["The training set contains 1963 sentences, has a maximum sequence length of 249 and a minimum of 1.\n","The validation set contains 1299 sentences, has a maximum sequence length of 81 and a minimum of 2.\n","The test set contains 652 sentences, has a maximum sequence length of 58 and a minimum of 2.\n"]}],"source":["training = get_matrixes(df_train, maximum_sequence_length, word2idx, tag2idx)\n","validation = get_matrixes(df_val, maximum_sequence_length, word2idx, tag2idx)\n","test = get_matrixes(df_test, maximum_sequence_length, word2idx, tag2idx)\n","\n","print(f'The training set contains {training[0].shape[0]} sentences, has a maximum sequence length of {get_info(df_train)[1]} and a minimum of {get_info(df_train)[3]}.')\n","print(f'The validation set contains {validation[0].shape[0]} sentences, has a maximum sequence length of {get_info(df_val)[1]} and a minimum of {get_info(df_val)[3]}.')\n","print(f'The test set contains {test[0].shape[0]} sentences, has a maximum sequence length of {get_info(df_test)[1]} and a minimum of {get_info(df_val)[3]}.')"]},{"cell_type":"markdown","source":["### Weights for unbalanced dataset\n","We also created a vector of weights for each POS tagging classes, to take into account the unbalance of the dataset, based on their inverse frequency.\n","The weights are amplified with a constant factor to avoid too low loss function during training, since it would be more difficult to track."],"metadata":{"id":"x4iRifuWsBEX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eIi4ToblGY56"},"outputs":[],"source":["def scale01(arr: np.ndarray):\n","    return (arr - np.min(arr)) / (np.max(arr) - np.min(arr))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1639818377105,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"},"user_tz":-60},"id":"2UwSQ23cdGrU","outputId":"8d748cea-f545-4ac1-fecc-83032fe5c0c0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.00000000e+00, 1.00000000e+04, 3.12272078e+01, 2.49418259e+01,\n","       3.86933702e+00, 1.95959672e+02, 1.85066294e+02, 5.00713295e+00,\n","       3.70540372e+01, 8.72853042e+00, 6.95108715e+00, 2.33469112e+00,\n","       2.03962970e+02, 4.99993943e+03, 1.90031731e+00, 3.23686474e+00,\n","       6.35739048e+01, 1.07407050e+02, 9.99890979e+02, 2.42694051e+01,\n","       1.48067911e+00, 1.84700605e+00, 1.05143299e+02, 3.21335090e+00,\n","       1.11100344e+03, 2.46930621e+01, 1.03831946e+01, 2.43889665e+01,\n","       6.59486377e+00, 1.16159344e+02, 5.26201031e+02, 7.13083024e+01,\n","       1.00000000e+04, 9.61608199e+00, 1.00000000e+04, 8.27527303e+00,\n","       6.34306811e+00, 1.29851844e+01, 9.60660999e+00, 1.36341905e+01,\n","       8.70509794e+00, 4.88990673e+01, 7.08017106e+01, 1.66656572e+03,\n","       1.09770307e+02, 2.43290396e+01])"]},"metadata":{},"execution_count":24}],"source":["# Obtain weighting for all the classes.\n","unique, counts = np.unique(np.squeeze(training[1], axis = -1), return_counts = True)\n","inverse_count = 1/counts\n","\n","weights = dict(zip(unique, inverse_count))\n","\n","weights_list = np.array(list(weights.values()))\n","weights_list = 1e4 * scale01(weights_list) # Amplify weights to better visualize loss.\n","weights_list"]},{"cell_type":"markdown","metadata":{"id":"bOISHI_Ea3Og"},"source":["## Models"]},{"cell_type":"markdown","metadata":{"id":"3sP0C6nK_kvJ"},"source":["### Baseline model:  bidirectional LSTM with fully connected layer\n","We created a baseline model, composed by three layers: a non-trainable embedding layer, that also takes into account the masking of the 0s used for padding, a bidirectional LSTM layer with a dense layer on top for classification.\n","The dense layer has the same number of nodes of the considered tags plus one, since we reserved 0 for padding."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1025,"status":"ok","timestamp":1639821526398,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"},"user_tz":-60},"id":"4nKl0HJyrAFo","outputId":"a578b1eb-a72f-4720-c06a-676652426fb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_17 (InputLayer)       [(None, 66)]              0         \n","                                                                 \n"," embedding_14 (Embedding)    (None, 66, 300)           4870200   \n","                                                                 \n"," bidirectional_6 (Bidirectio  (None, 66, 256)          439296    \n"," nal)                                                            \n","                                                                 \n"," time_distributed_6 (TimeDis  (None, 66, 46)           11822     \n"," tributed)                                                       \n","                                                                 \n","=================================================================\n","Total params: 5,321,318\n","Trainable params: 451,118\n","Non-trainable params: 4,870,200\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.layers import LSTM, Bidirectional, Dense, TimeDistributed, Input, Masking, Embedding\n","from tensorflow.keras.initializers import Constant\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.optimizers.schedules import ExponentialDecay\n","\n","hidden_nodes = 128\n","number_of_tags = get_info(df_train)[2] + 1 # Note: +1 since we reserved 0 for padding.\n","\n","sequence_input = Input(shape = (maximum_sequence_length, ))\n","#masked_input = Masking(mask_value = 0)(sequence_input)\n","\n","embedding_layer = Embedding(input_dim = embedding_matrix.shape[0],\n","                            output_dim = 300,\n","                            mask_zero = True,\n","                            embeddings_initializer = Constant(embedding_matrix),\n","                            trainable = False)(sequence_input)\n","\n","lstm_layer = Bidirectional(LSTM(hidden_nodes, return_sequences = True, dropout = 0.20, recurrent_dropout = 0.10))(embedding_layer)\n","sequence_output = TimeDistributed(Dense(number_of_tags, activation = 'softmax'))(lstm_layer)\n","\n","bidirect_model = Model(sequence_input, sequence_output)\n","\n","# Compile the model.\n","initial_learning_rate = 0.001\n","scheduler = ExponentialDecay(initial_learning_rate,\n","                             decay_steps = 100000,\n","                             decay_rate = 0.96,\n","                             staircase = True)\n","\n","bidirect_model.compile(loss = 'sparse_categorical_crossentropy', \n","                       #loss = focal_loss.SparseCategoricalFocalLoss(gamma = 2, class_weight = weights_list),\n","                       optimizer = RMSprop(learning_rate = scheduler),\n","                       metrics = ['acc'])\n","\n","# Check if the structure is correct.\n","bidirect_model.summary()"]},{"cell_type":"markdown","source":["For embedding we decided to choose the maximum available dimension for GloVe (300) to have the best possible representation.\n","\n","We performed a grid search between [16; 256], stepping with powers of two, to choose the number of hidden nodes of the LSTM layer: we obtained as best result 128 hidden nodes. We chose to dropout the 20\\% of nodes and the 10\\% of recurrent nodes of the LSTM layer.\n","\n","We trained our networks with RMSprop optimizer, using a learning rate scheduler that decays exponentially the rate, which starts at 0.001. We also tried Adam optimizer, but adaptative methods seems to stall the learning. \n","\n","As loss we used sparse categorical cross-entropy with softmax activation function for the last layer since we worked with integer labels. We also tried sparse categorical focal loss with class weights to enhance the dataset unbalance, but it turned out too difficult to optimize."],"metadata":{"id":"Whp483zV8hqW"}},{"cell_type":"markdown","source":["To early stop the training we tracked the validation loss, with a patience of 5 epochs, since the validation accuracy also takes into account the classes that we would later discard for evaluation."],"metadata":{"id":"txJdKs4Ww1lL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1B8thhix6zYL"},"outputs":[],"source":["checkpoint = [EarlyStopping(monitor = \"val_loss\", \n","                            patience = 5,\n","                            verbose = 1,\n","                            mode = \"auto\")]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r3CycEXI7IlQ","outputId":"3a66b871-0a1e-4daf-d6cf-e0ced3c278aa","executionInfo":{"status":"ok","timestamp":1639822460395,"user_tz":-60,"elapsed":928659,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","62/62 [==============================] - 44s 603ms/step - loss: 0.7279 - acc: 0.4718 - val_loss: 0.5629 - val_acc: 0.5571\n","Epoch 2/50\n","62/62 [==============================] - 37s 591ms/step - loss: 0.4491 - acc: 0.6505 - val_loss: 0.4406 - val_acc: 0.6367\n","Epoch 3/50\n","62/62 [==============================] - 36s 588ms/step - loss: 0.3592 - acc: 0.7113 - val_loss: 0.3782 - val_acc: 0.6902\n","Epoch 4/50\n","62/62 [==============================] - 37s 592ms/step - loss: 0.3118 - acc: 0.7460 - val_loss: 0.3543 - val_acc: 0.7047\n","Epoch 5/50\n","62/62 [==============================] - 37s 595ms/step - loss: 0.2803 - acc: 0.7681 - val_loss: 0.3304 - val_acc: 0.7252\n","Epoch 6/50\n","62/62 [==============================] - 36s 588ms/step - loss: 0.2548 - acc: 0.7873 - val_loss: 0.3169 - val_acc: 0.7375\n","Epoch 7/50\n","62/62 [==============================] - 37s 598ms/step - loss: 0.2330 - acc: 0.8062 - val_loss: 0.3028 - val_acc: 0.7486\n","Epoch 8/50\n","62/62 [==============================] - 37s 596ms/step - loss: 0.2147 - acc: 0.8231 - val_loss: 0.2912 - val_acc: 0.7606\n","Epoch 9/50\n","62/62 [==============================] - 37s 596ms/step - loss: 0.1982 - acc: 0.8371 - val_loss: 0.3024 - val_acc: 0.7460\n","Epoch 10/50\n","62/62 [==============================] - 37s 594ms/step - loss: 0.1830 - acc: 0.8496 - val_loss: 0.2846 - val_acc: 0.7659\n","Epoch 11/50\n","62/62 [==============================] - 36s 586ms/step - loss: 0.1688 - acc: 0.8617 - val_loss: 0.2723 - val_acc: 0.7757\n","Epoch 12/50\n","62/62 [==============================] - 37s 591ms/step - loss: 0.1561 - acc: 0.8735 - val_loss: 0.2689 - val_acc: 0.7806\n","Epoch 13/50\n","62/62 [==============================] - 37s 595ms/step - loss: 0.1441 - acc: 0.8837 - val_loss: 0.2689 - val_acc: 0.7826\n","Epoch 14/50\n","62/62 [==============================] - 37s 602ms/step - loss: 0.1341 - acc: 0.8919 - val_loss: 0.2644 - val_acc: 0.7857\n","Epoch 15/50\n","62/62 [==============================] - 37s 600ms/step - loss: 0.1241 - acc: 0.9015 - val_loss: 0.2664 - val_acc: 0.7817\n","Epoch 16/50\n","62/62 [==============================] - 37s 602ms/step - loss: 0.1152 - acc: 0.9091 - val_loss: 0.2631 - val_acc: 0.7891\n","Epoch 17/50\n","62/62 [==============================] - 37s 596ms/step - loss: 0.1054 - acc: 0.9166 - val_loss: 0.2579 - val_acc: 0.7962\n","Epoch 18/50\n","62/62 [==============================] - 37s 594ms/step - loss: 0.0972 - acc: 0.9248 - val_loss: 0.2577 - val_acc: 0.7952\n","Epoch 19/50\n","62/62 [==============================] - 37s 599ms/step - loss: 0.0894 - acc: 0.9311 - val_loss: 0.2703 - val_acc: 0.7882\n","Epoch 20/50\n","62/62 [==============================] - 37s 600ms/step - loss: 0.0826 - acc: 0.9370 - val_loss: 0.2565 - val_acc: 0.8009\n","Epoch 21/50\n","62/62 [==============================] - 37s 598ms/step - loss: 0.0769 - acc: 0.9416 - val_loss: 0.2716 - val_acc: 0.7913\n","Epoch 22/50\n","62/62 [==============================] - 37s 595ms/step - loss: 0.0694 - acc: 0.9483 - val_loss: 0.2567 - val_acc: 0.8025\n","Epoch 23/50\n","62/62 [==============================] - 37s 601ms/step - loss: 0.0646 - acc: 0.9526 - val_loss: 0.2591 - val_acc: 0.8037\n","Epoch 24/50\n","62/62 [==============================] - 37s 591ms/step - loss: 0.0590 - acc: 0.9569 - val_loss: 0.2603 - val_acc: 0.8026\n","Epoch 25/50\n","62/62 [==============================] - 37s 593ms/step - loss: 0.0538 - acc: 0.9613 - val_loss: 0.2628 - val_acc: 0.8043\n","Epoch 00025: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbec1f0ad10>"]},"metadata":{},"execution_count":84}],"source":["# Train the model.\n","bidirect_model.fit(x = training[0], y = training[1], \n","                   epochs = 50, callbacks = checkpoint,\n","                   validation_data = (validation[0], validation[1]))"]},{"cell_type":"markdown","metadata":{"id":"x-NZQa0jAmTp"},"source":["### Variation No. 1: bidirectional GRU with fully connected layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FbWjDUMIjpbi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639823759154,"user_tz":-60,"elapsed":1172204,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"}},"outputId":"2dfb77fe-a801-4b4b-e976-35e8ef629121"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_20 (InputLayer)       [(None, 66)]              0         \n","                                                                 \n"," embedding_17 (Embedding)    (None, 66, 300)           4870200   \n","                                                                 \n"," bidirectional_9 (Bidirectio  (None, 66, 256)          330240    \n"," nal)                                                            \n","                                                                 \n"," time_distributed_9 (TimeDis  (None, 66, 46)           11822     \n"," tributed)                                                       \n","                                                                 \n","=================================================================\n","Total params: 5,212,262\n","Trainable params: 342,062\n","Non-trainable params: 4,870,200\n","_________________________________________________________________\n","Epoch 1/50\n","62/62 [==============================] - 55s 742ms/step - loss: 0.6443 - acc: 0.5337 - val_loss: 0.4855 - val_acc: 0.6035\n","Epoch 2/50\n","62/62 [==============================] - 60s 965ms/step - loss: 0.3852 - acc: 0.6921 - val_loss: 0.3878 - val_acc: 0.6799\n","Epoch 3/50\n","62/62 [==============================] - 59s 956ms/step - loss: 0.3186 - acc: 0.7393 - val_loss: 0.3454 - val_acc: 0.7147\n","Epoch 4/50\n","62/62 [==============================] - 59s 956ms/step - loss: 0.2811 - acc: 0.7677 - val_loss: 0.3297 - val_acc: 0.7258\n","Epoch 5/50\n","62/62 [==============================] - 50s 805ms/step - loss: 0.2549 - acc: 0.7867 - val_loss: 0.3069 - val_acc: 0.7441\n","Epoch 6/50\n","62/62 [==============================] - 39s 628ms/step - loss: 0.2323 - acc: 0.8081 - val_loss: 0.2958 - val_acc: 0.7570\n","Epoch 7/50\n","62/62 [==============================] - 38s 607ms/step - loss: 0.2144 - acc: 0.8199 - val_loss: 0.2859 - val_acc: 0.7616\n","Epoch 8/50\n","62/62 [==============================] - 39s 633ms/step - loss: 0.1974 - acc: 0.8359 - val_loss: 0.2762 - val_acc: 0.7749\n","Epoch 9/50\n","62/62 [==============================] - 39s 634ms/step - loss: 0.1818 - acc: 0.8477 - val_loss: 0.2849 - val_acc: 0.7616\n","Epoch 10/50\n","62/62 [==============================] - 38s 612ms/step - loss: 0.1707 - acc: 0.8596 - val_loss: 0.2689 - val_acc: 0.7789\n","Epoch 11/50\n","62/62 [==============================] - 38s 613ms/step - loss: 0.1560 - acc: 0.8716 - val_loss: 0.2591 - val_acc: 0.7894\n","Epoch 12/50\n","62/62 [==============================] - 38s 610ms/step - loss: 0.1454 - acc: 0.8824 - val_loss: 0.2563 - val_acc: 0.7928\n","Epoch 13/50\n","62/62 [==============================] - 38s 614ms/step - loss: 0.1342 - acc: 0.8903 - val_loss: 0.2537 - val_acc: 0.7953\n","Epoch 14/50\n","62/62 [==============================] - 38s 616ms/step - loss: 0.1236 - acc: 0.8989 - val_loss: 0.2536 - val_acc: 0.8007\n","Epoch 15/50\n","62/62 [==============================] - 38s 611ms/step - loss: 0.1146 - acc: 0.9078 - val_loss: 0.2593 - val_acc: 0.7890\n","Epoch 16/50\n","62/62 [==============================] - 37s 601ms/step - loss: 0.1073 - acc: 0.9125 - val_loss: 0.2498 - val_acc: 0.7999\n","Epoch 17/50\n","62/62 [==============================] - 37s 598ms/step - loss: 0.0987 - acc: 0.9219 - val_loss: 0.2489 - val_acc: 0.8039\n","Epoch 18/50\n","62/62 [==============================] - 37s 600ms/step - loss: 0.0902 - acc: 0.9273 - val_loss: 0.2506 - val_acc: 0.8044\n","Epoch 19/50\n","62/62 [==============================] - 37s 596ms/step - loss: 0.0835 - acc: 0.9343 - val_loss: 0.2670 - val_acc: 0.7936\n","Epoch 20/50\n","62/62 [==============================] - 37s 600ms/step - loss: 0.0787 - acc: 0.9388 - val_loss: 0.2480 - val_acc: 0.8097\n","Epoch 21/50\n","62/62 [==============================] - 38s 610ms/step - loss: 0.0728 - acc: 0.9430 - val_loss: 0.2509 - val_acc: 0.8088\n","Epoch 22/50\n","62/62 [==============================] - 38s 613ms/step - loss: 0.0663 - acc: 0.9490 - val_loss: 0.2450 - val_acc: 0.8130\n","Epoch 23/50\n","62/62 [==============================] - 38s 609ms/step - loss: 0.0616 - acc: 0.9528 - val_loss: 0.2517 - val_acc: 0.8116\n","Epoch 24/50\n","62/62 [==============================] - 38s 610ms/step - loss: 0.0567 - acc: 0.9567 - val_loss: 0.2535 - val_acc: 0.8129\n","Epoch 25/50\n","62/62 [==============================] - 38s 608ms/step - loss: 0.0525 - acc: 0.9600 - val_loss: 0.2552 - val_acc: 0.8129\n","Epoch 26/50\n","62/62 [==============================] - 38s 610ms/step - loss: 0.0484 - acc: 0.9633 - val_loss: 0.2561 - val_acc: 0.8139\n","Epoch 27/50\n","62/62 [==============================] - 38s 610ms/step - loss: 0.0442 - acc: 0.9677 - val_loss: 0.2660 - val_acc: 0.8112\n","Epoch 00027: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbebd38c390>"]},"metadata":{},"execution_count":87}],"source":["from tensorflow.keras.layers import GRU, Bidirectional, Dense, TimeDistributed, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","hidden_nodes = 128\n","number_of_tags = get_info(df_train)[2] + 1 # Note: +1 since we reserved 0 for padding.\n","\n","sequence_input = Input(shape = (maximum_sequence_length, ))\n","#masked_input = Masking(mask_value = 0)(sequence_input)\n","\n","embedding_layer = Embedding(input_dim = embedding_matrix.shape[0],\n","                            output_dim = 300,\n","                            mask_zero = True,\n","                            embeddings_initializer = Constant(embedding_matrix),\n","                            trainable = False)(sequence_input)\n","\n","lstm_layer = Bidirectional(GRU(hidden_nodes, return_sequences = True, dropout = 0.20, recurrent_dropout = 0.10))(embedding_layer)\n","sequence_output = TimeDistributed(Dense(number_of_tags, activation = 'softmax'))(lstm_layer)\n","\n","bidirect_model_v1 = Model(sequence_input, sequence_output)\n","\n","# Compile the model.\n","initial_learning_rate = 0.001\n","scheduler = ExponentialDecay(initial_learning_rate,\n","                             decay_steps = 100000,\n","                             decay_rate = 0.96,\n","                             staircase = True)\n","\n","bidirect_model_v1.compile(loss = 'sparse_categorical_crossentropy', \n","                          #loss = focal_loss.SparseCategoricalFocalLoss(gamma = 2, class_weight = weights_list),\n","                          optimizer = RMSprop(learning_rate = scheduler),\n","                          metrics = ['acc'])\n","\n","# Check if the structure is correct.\n","bidirect_model_v1.summary()\n","\n","checkpoint = [EarlyStopping(monitor = \"val_loss\", \n","                            patience = 5,\n","                            verbose = 1,\n","                            mode = \"auto\")]\n","\n","# Train the model.\n","bidirect_model_v1.fit(x = training[0], y = training[1], epochs = 50, callbacks = checkpoint, validation_data = (validation[0], validation[1]))"]},{"cell_type":"markdown","metadata":{"id":"aRI7KFncA5JP"},"source":["### Variation No. 2: double bidirectional LSTM with fully connected layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NM3-VDXinOoX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639825327812,"user_tz":-60,"elapsed":1536037,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"}},"outputId":"7fda8dde-4f4d-4fd8-84c7-808ce5b54774"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_21 (InputLayer)       [(None, 66)]              0         \n","                                                                 \n"," embedding_18 (Embedding)    (None, 66, 300)           4870200   \n","                                                                 \n"," bidirectional_10 (Bidirecti  (None, 66, 256)          439296    \n"," onal)                                                           \n","                                                                 \n"," bidirectional_11 (Bidirecti  (None, 66, 256)          394240    \n"," onal)                                                           \n","                                                                 \n"," time_distributed_10 (TimeDi  (None, 66, 46)           11822     \n"," stributed)                                                      \n","                                                                 \n","=================================================================\n","Total params: 5,715,558\n","Trainable params: 845,358\n","Non-trainable params: 4,870,200\n","_________________________________________________________________\n","Epoch 1/50\n","62/62 [==============================] - 89s 1s/step - loss: 0.8341 - acc: 0.3718 - val_loss: 0.6227 - val_acc: 0.5075\n","Epoch 2/50\n","62/62 [==============================] - 75s 1s/step - loss: 0.5022 - acc: 0.6057 - val_loss: 0.4708 - val_acc: 0.6117\n","Epoch 3/50\n","62/62 [==============================] - 76s 1s/step - loss: 0.3834 - acc: 0.6873 - val_loss: 0.3922 - val_acc: 0.6748\n","Epoch 4/50\n","62/62 [==============================] - 76s 1s/step - loss: 0.3228 - acc: 0.7322 - val_loss: 0.3592 - val_acc: 0.6992\n","Epoch 5/50\n","62/62 [==============================] - 76s 1s/step - loss: 0.2832 - acc: 0.7622 - val_loss: 0.3313 - val_acc: 0.7213\n","Epoch 6/50\n","62/62 [==============================] - 76s 1s/step - loss: 0.2512 - acc: 0.7873 - val_loss: 0.3146 - val_acc: 0.7391\n","Epoch 7/50\n","62/62 [==============================] - 76s 1s/step - loss: 0.2249 - acc: 0.8099 - val_loss: 0.2928 - val_acc: 0.7540\n","Epoch 8/50\n","62/62 [==============================] - 76s 1s/step - loss: 0.2004 - acc: 0.8292 - val_loss: 0.2824 - val_acc: 0.7655\n","Epoch 9/50\n","62/62 [==============================] - 75s 1s/step - loss: 0.1815 - acc: 0.8462 - val_loss: 0.3032 - val_acc: 0.7496\n","Epoch 10/50\n","62/62 [==============================] - 75s 1s/step - loss: 0.1627 - acc: 0.8605 - val_loss: 0.2771 - val_acc: 0.7764\n","Epoch 11/50\n","62/62 [==============================] - 75s 1s/step - loss: 0.1450 - acc: 0.8774 - val_loss: 0.2614 - val_acc: 0.7864\n","Epoch 12/50\n","62/62 [==============================] - 76s 1s/step - loss: 0.1301 - acc: 0.8914 - val_loss: 0.2637 - val_acc: 0.7913\n","Epoch 13/50\n","62/62 [==============================] - 76s 1s/step - loss: 0.1172 - acc: 0.9001 - val_loss: 0.2615 - val_acc: 0.7940\n","Epoch 14/50\n","62/62 [==============================] - 75s 1s/step - loss: 0.1047 - acc: 0.9114 - val_loss: 0.2824 - val_acc: 0.7897\n","Epoch 15/50\n","62/62 [==============================] - 76s 1s/step - loss: 0.0931 - acc: 0.9214 - val_loss: 0.2611 - val_acc: 0.7977\n","Epoch 16/50\n","62/62 [==============================] - 76s 1s/step - loss: 0.0832 - acc: 0.9285 - val_loss: 0.2657 - val_acc: 0.8016\n","Epoch 17/50\n","62/62 [==============================] - 75s 1s/step - loss: 0.0737 - acc: 0.9390 - val_loss: 0.2683 - val_acc: 0.8043\n","Epoch 18/50\n","62/62 [==============================] - 75s 1s/step - loss: 0.0666 - acc: 0.9435 - val_loss: 0.2729 - val_acc: 0.8028\n","Epoch 19/50\n","62/62 [==============================] - 76s 1s/step - loss: 0.0584 - acc: 0.9495 - val_loss: 0.2820 - val_acc: 0.8035\n","Epoch 20/50\n","62/62 [==============================] - 76s 1s/step - loss: 0.0527 - acc: 0.9550 - val_loss: 0.2743 - val_acc: 0.8099\n","Epoch 00020: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbebbc6ed50>"]},"metadata":{},"execution_count":88}],"source":["from tensorflow.keras.layers import LSTM, Bidirectional, Dense, TimeDistributed, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","hidden_nodes = 128\n","number_of_tags = get_info(df_train)[2] + 1 # Note: +1 since we reserved 0 for padding.\n","\n","sequence_input = Input(shape = (maximum_sequence_length, ))\n","#masked_input = Masking(mask_value = 0)(sequence_input)\n","\n","embedding_layer = Embedding(input_dim = embedding_matrix.shape[0],\n","                            output_dim = 300,\n","                            mask_zero = True,\n","                            embeddings_initializer = Constant(embedding_matrix),\n","                            trainable = False)(sequence_input)\n","\n","lstm_layer_1 = Bidirectional(LSTM(hidden_nodes, return_sequences = True, dropout = 0.20, recurrent_dropout = 0.10))(embedding_layer)\n","lstm_layer_2 = Bidirectional(LSTM(hidden_nodes, return_sequences = True, dropout = 0.20, recurrent_dropout = 0.10))(lstm_layer_1)\n","sequence_output = TimeDistributed(Dense(number_of_tags, activation = 'softmax'))(lstm_layer_2)\n","\n","bidirect_model_v2 = Model(sequence_input, sequence_output)\n","\n","# Compile the model.\n","initial_learning_rate = 0.001\n","scheduler = ExponentialDecay(initial_learning_rate,\n","                             decay_steps = 100000,\n","                             decay_rate = 0.96,\n","                             staircase = True)\n","\n","bidirect_model_v2.compile(loss = 'sparse_categorical_crossentropy', \n","                          #loss = focal_loss.SparseCategoricalFocalLoss(gamma = 2, class_weight = weights_list),\n","                          optimizer = RMSprop(learning_rate = scheduler),\n","                          metrics = ['acc'])\n","\n","# Check if the structure is correct.\n","bidirect_model_v2.summary()\n","\n","checkpoint = [EarlyStopping(monitor = 'val_loss', \n","                            patience = 5,\n","                            verbose = 1,\n","                            mode = \"auto\")]\n","\n","# Train the model.\n","bidirect_model_v2.fit(x = training[0], y = training[1], epochs = 50, callbacks = checkpoint, validation_data = (validation[0], validation[1]))"]},{"cell_type":"markdown","metadata":{"id":"K_LHpoieBAHl"},"source":["### Variation No. 3: bidirectional LSTM with double fully connected layer\n","For the last variation we doubled the number of hidden nodes of the first dense layer."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4CbFzISMoC4b","executionInfo":{"status":"ok","timestamp":1639827633980,"user_tz":-60,"elapsed":1893607,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"}},"outputId":"ce375e2a-6495-4445-8011-71d500d29592"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_13\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_25 (InputLayer)       [(None, 66)]              0         \n","                                                                 \n"," embedding_22 (Embedding)    (None, 66, 300)           4870200   \n","                                                                 \n"," bidirectional_15 (Bidirecti  (None, 66, 256)          439296    \n"," onal)                                                           \n","                                                                 \n"," time_distributed_16 (TimeDi  (None, 66, 92)           23644     \n"," stributed)                                                      \n","                                                                 \n"," time_distributed_17 (TimeDi  (None, 66, 46)           4278      \n"," stributed)                                                      \n","                                                                 \n","=================================================================\n","Total params: 5,337,418\n","Trainable params: 467,218\n","Non-trainable params: 4,870,200\n","_________________________________________________________________\n","Epoch 1/50\n","62/62 [==============================] - 48s 620ms/step - loss: 1.3288 - acc: 0.2711 - val_loss: 1.2995 - val_acc: 0.3442\n","Epoch 2/50\n","62/62 [==============================] - 37s 605ms/step - loss: 1.2721 - acc: 0.3387 - val_loss: 1.2533 - val_acc: 0.3258\n","Epoch 3/50\n","62/62 [==============================] - 39s 629ms/step - loss: 1.2266 - acc: 0.3211 - val_loss: 1.2103 - val_acc: 0.3307\n","Epoch 4/50\n","62/62 [==============================] - 40s 640ms/step - loss: 1.1850 - acc: 0.3217 - val_loss: 1.1709 - val_acc: 0.3186\n","Epoch 5/50\n","62/62 [==============================] - 38s 610ms/step - loss: 1.1459 - acc: 0.3216 - val_loss: 1.1347 - val_acc: 0.3275\n","Epoch 6/50\n","62/62 [==============================] - 37s 600ms/step - loss: 1.1095 - acc: 0.3233 - val_loss: 1.1012 - val_acc: 0.3169\n","Epoch 7/50\n","62/62 [==============================] - 37s 604ms/step - loss: 1.0756 - acc: 0.3236 - val_loss: 1.0689 - val_acc: 0.3297\n","Epoch 8/50\n","62/62 [==============================] - 37s 598ms/step - loss: 1.0441 - acc: 0.3257 - val_loss: 1.0395 - val_acc: 0.3272\n","Epoch 9/50\n","62/62 [==============================] - 37s 603ms/step - loss: 1.0147 - acc: 0.3256 - val_loss: 1.0139 - val_acc: 0.3304\n","Epoch 10/50\n","62/62 [==============================] - 38s 612ms/step - loss: 0.9878 - acc: 0.3238 - val_loss: 0.9882 - val_acc: 0.3308\n","Epoch 11/50\n","62/62 [==============================] - 38s 607ms/step - loss: 0.9628 - acc: 0.3212 - val_loss: 0.9665 - val_acc: 0.3221\n","Epoch 12/50\n","62/62 [==============================] - 37s 603ms/step - loss: 0.9400 - acc: 0.3185 - val_loss: 0.9479 - val_acc: 0.3236\n","Epoch 13/50\n","62/62 [==============================] - 37s 604ms/step - loss: 0.9194 - acc: 0.3160 - val_loss: 0.9287 - val_acc: 0.3219\n","Epoch 14/50\n","62/62 [==============================] - 38s 607ms/step - loss: 0.8980 - acc: 0.3153 - val_loss: 0.9110 - val_acc: 0.3178\n","Epoch 15/50\n","62/62 [==============================] - 37s 601ms/step - loss: 0.8788 - acc: 0.3140 - val_loss: 0.8913 - val_acc: 0.3197\n","Epoch 16/50\n","62/62 [==============================] - 37s 605ms/step - loss: 0.8622 - acc: 0.3138 - val_loss: 0.8768 - val_acc: 0.3190\n","Epoch 17/50\n","62/62 [==============================] - 38s 606ms/step - loss: 0.8466 - acc: 0.3176 - val_loss: 0.8659 - val_acc: 0.3209\n","Epoch 18/50\n","62/62 [==============================] - 38s 607ms/step - loss: 0.8322 - acc: 0.3192 - val_loss: 0.8546 - val_acc: 0.3242\n","Epoch 19/50\n","62/62 [==============================] - 38s 608ms/step - loss: 0.8192 - acc: 0.3198 - val_loss: 0.8412 - val_acc: 0.3245\n","Epoch 20/50\n","62/62 [==============================] - 38s 607ms/step - loss: 0.8069 - acc: 0.3205 - val_loss: 0.8328 - val_acc: 0.3239\n","Epoch 21/50\n","62/62 [==============================] - 38s 607ms/step - loss: 0.7963 - acc: 0.3208 - val_loss: 0.8258 - val_acc: 0.3258\n","Epoch 22/50\n","62/62 [==============================] - 37s 605ms/step - loss: 0.7868 - acc: 0.3212 - val_loss: 0.8169 - val_acc: 0.3245\n","Epoch 23/50\n","62/62 [==============================] - 38s 611ms/step - loss: 0.7777 - acc: 0.3212 - val_loss: 0.8122 - val_acc: 0.3255\n","Epoch 24/50\n","62/62 [==============================] - 38s 610ms/step - loss: 0.7694 - acc: 0.3213 - val_loss: 0.8055 - val_acc: 0.3220\n","Epoch 25/50\n","62/62 [==============================] - 38s 606ms/step - loss: 0.7619 - acc: 0.3213 - val_loss: 0.8004 - val_acc: 0.3253\n","Epoch 26/50\n","62/62 [==============================] - 38s 612ms/step - loss: 0.7549 - acc: 0.3216 - val_loss: 0.7934 - val_acc: 0.3254\n","Epoch 27/50\n","62/62 [==============================] - 38s 610ms/step - loss: 0.7483 - acc: 0.3216 - val_loss: 0.7901 - val_acc: 0.3251\n","Epoch 28/50\n","62/62 [==============================] - 37s 603ms/step - loss: 0.7423 - acc: 0.3216 - val_loss: 0.7857 - val_acc: 0.3244\n","Epoch 29/50\n","62/62 [==============================] - 38s 609ms/step - loss: 0.7367 - acc: 0.3216 - val_loss: 0.7833 - val_acc: 0.3261\n","Epoch 30/50\n","62/62 [==============================] - 37s 605ms/step - loss: 0.7317 - acc: 0.3219 - val_loss: 0.7791 - val_acc: 0.3241\n","Epoch 31/50\n","62/62 [==============================] - 37s 605ms/step - loss: 0.7271 - acc: 0.3218 - val_loss: 0.7785 - val_acc: 0.3221\n","Epoch 32/50\n","62/62 [==============================] - 37s 605ms/step - loss: 0.7231 - acc: 0.3219 - val_loss: 0.7763 - val_acc: 0.3263\n","Epoch 33/50\n","62/62 [==============================] - 37s 601ms/step - loss: 0.7189 - acc: 0.3221 - val_loss: 0.7723 - val_acc: 0.3261\n","Epoch 34/50\n","62/62 [==============================] - 37s 604ms/step - loss: 0.7154 - acc: 0.3222 - val_loss: 0.7701 - val_acc: 0.3255\n","Epoch 35/50\n","62/62 [==============================] - 37s 605ms/step - loss: 0.7118 - acc: 0.3223 - val_loss: 0.7654 - val_acc: 0.3247\n","Epoch 36/50\n","62/62 [==============================] - 38s 608ms/step - loss: 0.7080 - acc: 0.3227 - val_loss: 0.7631 - val_acc: 0.3252\n","Epoch 37/50\n","62/62 [==============================] - 38s 605ms/step - loss: 0.7046 - acc: 0.3233 - val_loss: 0.7615 - val_acc: 0.3255\n","Epoch 38/50\n","62/62 [==============================] - 37s 601ms/step - loss: 0.7012 - acc: 0.3233 - val_loss: 0.7618 - val_acc: 0.3259\n","Epoch 39/50\n","62/62 [==============================] - 37s 599ms/step - loss: 0.6980 - acc: 0.3238 - val_loss: 0.7561 - val_acc: 0.3253\n","Epoch 40/50\n","62/62 [==============================] - 37s 602ms/step - loss: 0.6948 - acc: 0.3245 - val_loss: 0.7557 - val_acc: 0.3269\n","Epoch 41/50\n","62/62 [==============================] - 37s 603ms/step - loss: 0.6919 - acc: 0.3248 - val_loss: 0.7543 - val_acc: 0.3264\n","Epoch 42/50\n","62/62 [==============================] - 37s 604ms/step - loss: 0.6889 - acc: 0.3260 - val_loss: 0.7490 - val_acc: 0.3268\n","Epoch 43/50\n","62/62 [==============================] - 37s 603ms/step - loss: 0.6860 - acc: 0.3270 - val_loss: 0.7490 - val_acc: 0.3269\n","Epoch 44/50\n","62/62 [==============================] - 37s 601ms/step - loss: 0.6827 - acc: 0.3291 - val_loss: 0.7459 - val_acc: 0.3277\n","Epoch 45/50\n","62/62 [==============================] - 38s 608ms/step - loss: 0.6793 - acc: 0.3305 - val_loss: 0.7413 - val_acc: 0.3290\n","Epoch 46/50\n","62/62 [==============================] - 37s 602ms/step - loss: 0.6753 - acc: 0.3317 - val_loss: 0.7365 - val_acc: 0.3302\n","Epoch 47/50\n","62/62 [==============================] - 37s 601ms/step - loss: 0.6712 - acc: 0.3353 - val_loss: 0.7328 - val_acc: 0.3334\n","Epoch 48/50\n","62/62 [==============================] - 37s 601ms/step - loss: 0.6669 - acc: 0.3397 - val_loss: 0.7295 - val_acc: 0.3386\n","Epoch 49/50\n","62/62 [==============================] - 38s 606ms/step - loss: 0.6622 - acc: 0.3477 - val_loss: 0.7259 - val_acc: 0.3416\n","Epoch 50/50\n","62/62 [==============================] - 38s 606ms/step - loss: 0.6563 - acc: 0.3632 - val_loss: 0.7182 - val_acc: 0.3480\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbebedf3850>"]},"metadata":{},"execution_count":92}],"source":["from tensorflow.keras.layers import LSTM, Bidirectional, Dense, TimeDistributed, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","hidden_nodes = 128\n","number_of_tags = get_info(df_train)[2] + 1 # Note: +1 since we reserved 0 for padding.\n","\n","sequence_input = Input(shape = (maximum_sequence_length, ))\n","#masked_input = Masking(mask_value = 0)(sequence_input)\n","\n","embedding_layer = Embedding(input_dim = embedding_matrix.shape[0],\n","                            output_dim = 300,\n","                            mask_zero = True,\n","                            embeddings_initializer = Constant(embedding_matrix),\n","                            trainable = False)(sequence_input)\n","\n","lstm_layer = Bidirectional(LSTM(hidden_nodes, return_sequences = True, dropout = 0.20, recurrent_dropout = 0.10))(embedding_layer)\n","dense_layer = TimeDistributed(Dense(2 * number_of_tags, activation = 'softmax'))(lstm_layer)\n","sequence_output = TimeDistributed(Dense(number_of_tags, activation = 'softmax'))(dense_layer)\n","\n","bidirect_model_v3 = Model(sequence_input, sequence_output)\n","\n","# Compile the model.\n","initial_learning_rate = 0.001\n","scheduler = ExponentialDecay(initial_learning_rate,\n","                             decay_steps = 100000,\n","                             decay_rate = 0.96,\n","                             staircase = True)\n","\n","bidirect_model_v3.compile(loss = 'sparse_categorical_crossentropy', \n","                          #loss = focal_loss.SparseCategoricalFocalLoss(gamma = 2, class_weight = weights_list),\n","                          optimizer = RMSprop(learning_rate = scheduler),\n","                          metrics = ['acc'])\n","\n","# Check if the structure is correct.\n","bidirect_model_v3.summary()\n","\n","checkpoint = [EarlyStopping(monitor = \"val_loss\", \n","                            patience = 5,\n","                            verbose = 1,\n","                            mode = \"auto\")]\n","\n","# Train the model.\n","bidirect_model_v3.fit(x = training[0], y = training[1], epochs = 50, callbacks = checkpoint, validation_data = (validation[0], validation[1]))"]},{"cell_type":"markdown","metadata":{"id":"63JrISyBo-cd"},"source":[" ## Evaluation"]},{"cell_type":"code","source":["tag2idx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pq3QDRVKWNUK","executionInfo":{"status":"ok","timestamp":1639827698487,"user_tz":-60,"elapsed":418,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"}},"outputId":"ee677a87-96fb-4201-92e8-836fedff6c5d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('#', 1),\n","             ('$', 2),\n","             (\"''\", 3),\n","             (',', 4),\n","             ('-LRB-', 5),\n","             ('-RRB-', 6),\n","             ('.', 7),\n","             (':', 8),\n","             ('CC', 9),\n","             ('CD', 10),\n","             ('DT', 11),\n","             ('EX', 12),\n","             ('FW', 13),\n","             ('IN', 14),\n","             ('JJ', 15),\n","             ('JJR', 16),\n","             ('JJS', 17),\n","             ('LS', 18),\n","             ('MD', 19),\n","             ('NN', 20),\n","             ('NNP', 21),\n","             ('NNPS', 22),\n","             ('NNS', 23),\n","             ('PDT', 24),\n","             ('POS', 25),\n","             ('PRP', 26),\n","             ('PRP$', 27),\n","             ('RB', 28),\n","             ('RBR', 29),\n","             ('RBS', 30),\n","             ('RP', 31),\n","             ('SYM', 32),\n","             ('TO', 32),\n","             ('UH', 33),\n","             ('VB', 34),\n","             ('VBD', 35),\n","             ('VBG', 36),\n","             ('VBN', 37),\n","             ('VBP', 38),\n","             ('VBZ', 39),\n","             ('WDT', 40),\n","             ('WP', 41),\n","             ('WP$', 42),\n","             ('WRB', 43),\n","             ('``', 44)])"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"njD0l4isudgS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639827830839,"user_tz":-60,"elapsed":7,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"}},"outputId":"d605c5d6-3f32-40de-a718-de72bd00d777"},"outputs":[{"output_type":"stream","name":"stdout","text":["The meaningful classes are: [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43].\n"]},{"output_type":"execute_result","data":{"text/plain":["35"]},"metadata":{},"execution_count":96}],"source":["punctuation_indexes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 44]\n","meaningful_classes = list(set([i for i in range(0,45)]).difference(set(punctuation_indexes)))\n","print(f'The meaningful classes are: {meaningful_classes}.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dEO_185SfDMT"},"outputs":[],"source":["from sklearn.metrics import classification_report, f1_score, confusion_matrix, accuracy_score\n","\n","def evaluate_model(model: tf.keras.Model, test_matrix: np.ndarray):\n","  prediction = model.predict(test_matrix[0]) # Evaluate the test set.\n","\n","  prediction = np.argmax(prediction, axis = -1) # Get the class with the highest index.\n","  #prediction = np.expand_dims(prediction, axis = -1) # Add dimension to to conform it to the prediction.\n","\n","  print(f'Evaluation for model {model}.')\n","  print(classification_report(y_true = np.squeeze(test_matrix[1], axis = -1).ravel(), y_pred = prediction.ravel(), zero_division = 0, labels = meaningful_classes))\n","\n","\n","  print(f'The f1-score, calculated on the meaningful classes of the test set, is: {f1_score(y_true = np.squeeze(test_matrix[1], axis = -1).ravel(), y_pred = prediction.ravel(), average = \"macro\", zero_division = 0, labels = meaningful_classes)}.')\n","  print(f'The global accuracy score on the test set is: {accuracy_score(y_true = np.squeeze(test_matrix[1], axis = -1).ravel(), y_pred = prediction.ravel())}.')\n","\n","  return confusion_matrix(y_true = np.squeeze(test_matrix[1], axis = -1).ravel(), y_pred = prediction.ravel(), labels = meaningful_classes)"]},{"cell_type":"markdown","source":["The best models are variation one and two.\n"],"metadata":{"id":"g9r776Z480FU"}},{"cell_type":"code","source":["#cf = evaluate_model(bidirect_model, test)\n","cf_v1 = evaluate_model(bidirect_model_v1, test)\n","cf_v2 = evaluate_model(bidirect_model_v2, test)\n","#cf_v3 = evaluate_model(bidirect_model_v3, test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d-9DryPp-xm9","executionInfo":{"status":"ok","timestamp":1639828872701,"user_tz":-60,"elapsed":5306,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"}},"outputId":"1ec689a9-2129-44e1-b8a8-7b3890a1065a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluation for model <keras.engine.functional.Functional object at 0x7fbebd410d10>.\n","              precision    recall  f1-score   support\n","\n","           9       0.98      1.00      0.99       366\n","          10       0.92      0.78      0.85       858\n","          11       0.97      0.98      0.98      1335\n","          12       0.71      1.00      0.83         5\n","          13       1.00      1.00      1.00         0\n","          14       0.95      0.96      0.95      1630\n","          15       0.58      0.63      0.60       918\n","          16       0.65      0.56      0.60        59\n","          17       0.77      0.65      0.70        31\n","          18       0.00      1.00      0.00         0\n","          19       0.95      0.99      0.97       167\n","          20       0.69      0.80      0.74      2383\n","          21       0.79      0.53      0.63      1504\n","          22       0.25      0.02      0.04        44\n","          23       0.67      0.69      0.68       941\n","          24       1.00      0.00      0.00         4\n","          25       0.99      0.99      0.99       152\n","          26       0.93      0.99      0.96       192\n","          27       0.82      1.00      0.90        99\n","          28       0.01      0.73      0.02       381\n","          29       0.19      0.27      0.22        15\n","          30       0.40      0.67      0.50         3\n","          31       0.45      0.61      0.52        33\n","          32       1.00      1.00      1.00       386\n","          33       1.00      1.00      1.00         0\n","          34       0.80      0.88      0.84       403\n","          35       0.84      0.77      0.80       634\n","          36       0.56      0.52      0.54       221\n","          37       0.61      0.65      0.63       366\n","          38       0.72      0.75      0.74       134\n","          39       0.86      0.78      0.82       280\n","          40       0.93      0.88      0.90        84\n","          41       0.91      1.00      0.95        20\n","          42       1.00      1.00      1.00         4\n","          43       0.92      0.96      0.94        24\n","\n","   micro avg       0.26      0.79      0.39     13676\n","   macro avg       0.74      0.77      0.71     13676\n","weighted avg       0.78      0.79      0.77     13676\n","\n","The f1-score, calculated on the meaningful classes of the test set, is: 0.6525947114372308.\n","The global accuracy score on the test set is: 0.2948271054099275.\n","Evaluation for model <keras.engine.functional.Functional object at 0x7fbebbcb8d10>.\n","              precision    recall  f1-score   support\n","\n","           9       0.98      1.00      0.99       366\n","          10       0.92      0.79      0.85       858\n","          11       0.97      0.98      0.98      1335\n","          12       0.71      1.00      0.83         5\n","          13       1.00      1.00      1.00         0\n","          14       0.96      0.96      0.96      1630\n","          15       0.64      0.51      0.56       918\n","          16       0.61      0.58      0.59        59\n","          17       0.60      0.48      0.54        31\n","          18       0.00      1.00      0.00         0\n","          19       0.96      0.97      0.97       167\n","          20       0.68      0.80      0.74      2383\n","          21       0.65      0.66      0.66      1504\n","          22       0.33      0.02      0.04        44\n","          23       0.70      0.67      0.68       941\n","          24       1.00      0.00      0.00         4\n","          25       0.99      1.00      1.00       152\n","          26       0.95      0.97      0.96       192\n","          27       0.85      0.99      0.92        99\n","          28       0.64      0.63      0.64       381\n","          29       0.14      0.07      0.09        15\n","          30       0.29      0.67      0.40         3\n","          31       0.44      0.58      0.50        33\n","          32       1.00      1.00      1.00       386\n","          33       1.00      1.00      1.00         0\n","          34       0.81      0.88      0.84       403\n","          35       0.86      0.80      0.83       634\n","          36       0.47      0.52      0.49       221\n","          37       0.78      0.58      0.67       366\n","          38       0.86      0.70      0.77       134\n","          39       0.81      0.80      0.80       280\n","          40       0.94      0.96      0.95        84\n","          41       0.95      1.00      0.98        20\n","          42       1.00      0.75      0.86         4\n","          43       0.91      0.88      0.89        24\n","\n","   micro avg       0.26      0.79      0.40     13676\n","   macro avg       0.75      0.75      0.71     13676\n","weighted avg       0.80      0.79      0.79     13676\n","\n","The f1-score, calculated on the meaningful classes of the test set, is: 0.6564178638545529.\n","The global accuracy score on the test set is: 0.29545454545454547.\n"]}]},{"cell_type":"markdown","source":["To calculate the F1-score we discarded the classes with null support in the test set. We could also consider their prediction 1 or 0, but we would overestimate or underestimate the score. The choice is application-dependent.\n","This is also the reason why we obtained such low accuracy scores on the test set."],"metadata":{"id":"l3RUjG5T8_GW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tFLljFOZ6Q1K"},"outputs":[],"source":["import math\n","\n","def compute_custom_metrics(conf_mat : np.ndarray):  \n","  accuracies, precisions, recalls, f1_scores = dict(), dict(), dict(), dict()\n","\n","  for i in range(len(conf_mat)):\n","    TP = conf_mat[i,i]\n","    FN = np.sum(conf_mat[i,:]) - conf_mat[i,i]\n","    FP = np.sum(conf_mat[:,i]) - conf_mat[i,i]\n","    TN = np.sum(conf_mat) - TP - FP - FN\n","\n","    accuracies[i] =  (TP + TN) / (TP + FP + FN + TN)\n","    precisions[i] =  TP / (TP + FP)\n","    recalls[i] = TP / (TP + FN)\n","    f1_scores[i] = 2 * (recalls[i] * precisions[i]) / (recalls[i] + precisions[i])\n","\n","  f1_scores_pruned = dict()\n","\n","  for k,v in f1_scores.items():\n","    if math.isnan(v) == False:\n","      f1_scores_pruned[k] = v\n","\n","  global_accuracy = np.mean(list(accuracies.values()))\n","  macro_f1 = np.mean(list(f1_scores_pruned.values()))\n","\n","  print(f'The global accuracy for the given confusion matrix is {global_accuracy}, with an f1-score of {macro_f1}.')\n","\n","  return global_accuracy, macro_f1"]},{"cell_type":"markdown","source":["Note, the accuracy displayed down here is referred to only the considered classes, with support. Actually global accuracy considers them all."],"metadata":{"id":"bbUDXxQ79EsT"}},{"cell_type":"code","source":["compute_custom_metrics(cf_v1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4xzxIc7pZYGe","executionInfo":{"status":"ok","timestamp":1639829754360,"user_tz":-60,"elapsed":419,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"}},"outputId":"7e27b9c6-04f9-43c6-8063-87e54c8ea49f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The global accuracy for the given confusion matrix is 0.9881545351806119, with an f1-score of 0.7571027270448055.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in long_scalars\n","  del sys.path[0]\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in long_scalars\n","  \n"]},{"output_type":"execute_result","data":{"text/plain":["(0.9881545351806119, 0.7571027270448055)"]},"metadata":{},"execution_count":140}]},{"cell_type":"code","source":["compute_custom_metrics(cf_v2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NNX74UvRZvku","executionInfo":{"status":"ok","timestamp":1639829776884,"user_tz":-60,"elapsed":469,"user":{"displayName":"Alex Costanzino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsssZEgQCu-_U5UnTxramtVjR0iEGdwDvQExA0DA=s64","userId":"15677494199636126887"}},"outputId":"e91165c5-3f10-4536-a8d2-9888c83ec4b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The global accuracy for the given confusion matrix is 0.9883092131442812, with an f1-score of 0.7421710391633364.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in long_scalars\n","  del sys.path[0]\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in long_scalars\n","  \n"]},{"output_type":"execute_result","data":{"text/plain":["(0.9883092131442812, 0.7421710391633364)"]},"metadata":{},"execution_count":141}]},{"cell_type":"code","source":[""],"metadata":{"id":"pyCK54_UeKYp"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"assignment_one.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}